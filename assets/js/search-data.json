{
  
    
        "post0": {
            "title": "(TH) Deep Learning with More Sensation",
            "content": "&#3648;&#3617;&#3639;&#3656;&#3629;&#3605;&#3657;&#3629;&#3591;&#3648;&#3612;&#3594;&#3636;&#3597;&#3627;&#3609;&#3657;&#3634;&#3585;&#3633;&#3610; Dataset . เมื่อเราต้องการที่จะสร้าง neural network program สิ่งที่เราต้องมีก็คือ dataset เปรียบได้กับมันคือคลังข้อมูลที่รอให้เราได้เข้าไปเรียนรู้ พอเราจบการเรียนรู้ เราก็จะมีความสามารถในการทำหรือแก้ปัญหาสิ่งนั้นๆตามที่เราได้เรียนหรือศึกษามา . MNIST Dataset . dataset อันนี้จะเป็นการรวมข้อมูลเกี่ยวกับ ตัวเลขที่ถูกเขียนด้วยลายมือมนุษย์ โดยได้มีการเก็บรวบรวมโดย National Institute of Standards and Technology และได้ถูกทำมาจัดรูปแบบและแก้ไขปรับปรุงให้เป็น dataset ที่ใช้สำหรับ machine learning โดย Yann Lecun MNIST ได้ถูก Yann Lecun นำไปใช้ในปี 1998 สำหรับการสร้าง neural network ซึ่ง LeNet-5 คือ program ตัวแรกที่ใช้สำหรับการจัดกลุ่มตัวเลขที่เขียนด้วยลายมือมนุษย์ นี่เป็นเหตุการณ์สำคัญอีกหน้าหนึ่งของประวัติศาสตร์ AI . &#3650;&#3629;&#3648;&#3588; &#3650;&#3629;&#3648;&#3588; &#3648;&#3619;&#3634;&#3617;&#3634;&#3621;&#3640;&#3618;&#3585;&#3633;&#3609;&#3648;&#3621;&#3618; . (x_train, y_train), (x_test, y_test) = datasets.mnist.load_data() print(f&quot;จำนวนข้อมูลใน Training set: {x_train.shape[0]}&quot;) print(f&quot;จำนวนข้อมูลใน Testing set: {x_test.shape[0]}&quot;) . จำนวนข้อมูลใน Training set: 60000 จำนวนข้อมูลใน Testing set: 10000 . เราทำการโหลดข้อมูล MNIST จาก Keras ซึ่งเป็น framework ที่ใช้สำหรับสร้าง neural network program โดย Keras จะมี datasets ที่เตรียมไว้ให้บางส่วน (MNIST ก็เป็นหนึ่งในนั้น) จะสังเกตได้ว่าข้อมูลจะถูกแบ่งแยกออกมาเป็น 2 ส่วนนั่นคือ training และ testing set ทำไมกันนะ? อย่างที่เรารู้ในตอนนี้คือ เราพยายามจะสร้าง prgram ด้วยข้อมูล เมื่อผลลัพธ์ทดสอบดูกับข้อมูลที่เราใช้สร้างแล้วความสามารถในการให้คำตอบเราดีเยี่ยม แต่ แต่... นี่ก็ไม่ได้การันตีว่า พอเรานำไปใช้จริงกับข้อมูลที่ไม่ได้อยู่ในกลุ่ม training จะเกิดอะไรชึ้น ดังนั้น เราเลยต้องมีข้อมูลอีกกลุ่มมาทำเพื่อทำการทดสอบว่าถ้าเป็นข้อมูลที่ไม่ได้อยู่ในกลุ่มที่ใช้เรียนรู้ ความรู้หรือ program ที่เราได้มา ยังจะสามารถแก้ไขปัญหาได้อย่างถูกต้องไหม . Note: แน่นอนว่า training และ testing set ข้อมูลข้างในจะต้องไม่ใช่ตัวเดียวกัน แต่คุณลักษณะของข้อมูลทั้ง 2 กลุ่มยังต้องใกล้เคียงกัน (มาจาก statistical distribution เดี่ยวกัน) เราคงไม่สามารถเอาความรู้ที่เรียนจากภาพถ่ายรูปมุมหนึ่ง ไปใช้กับปัญหาที่เป็นรูปประเภทเดียวกันแต่ถ่ายจากอีกมุมนึงที่ไม่ปรากฏในคลังข้อมูลที่ใช้เรียนรู้ . นอกจากที่ถ้าสังเกตเห็นมันจะมีข้อมูลอีก 2 ตัวแปรที่ขึ้นต้นด้วย &quot;y&quot; มันคืออะไรกันนะ? จริงๆแล้วมันหมายถึงตัวแปรที่เก็บ labels หรือก็คือคำตอบที่ถูกผูกติดกับตัวอย่าง โดยในแต่ละตัวอย่างก็จะถูกผูกกับ label เอ๊ะแล้วค่าในตัวอย่างมันเป็นอะไรได้บ้าง? เราจะประกาศว่าคำตอบของปัญหานี้เป็นอะไรได้บ้างซึ่งแต่ละคำตอบเราจะเรียกว่า class ดังนั้น MNIST ที่มีคำตอบที่เป็นไปได้คือ 0 - 9 จะมีคำตอบทั้งหมด 10 คำตอบ ถ้าเรามองเป็น predefined set of classes จะได้เป็น {0, 1, 2, 3, 4, 5, 6, 7, 8, 9} . &#3617;&#3634;&#3621;&#3629;&#3591;&#3604;&#3641;&#3605;&#3633;&#3623;&#3629;&#3618;&#3656;&#3634;&#3591;&#3585;&#3633;&#3609; . เดี๋ยวเราลองมาดูตัวอย่างแรกของ training set กัน . จากภาพและผลลัพธ์จะเห็นได้ว่าตัวอย่างอันแรกใน training set เป็นเลข 5 โดยภาพมีขนาด 28 x 28 (height x width เนื่องจาก numpy จะแสดง row ก่อนแล้วค่อย column) แต่ก่อนที่เราจะเริ่มสร้าง neural network program กัน เราต้องทำอะไรเพิ่มอีกหน่อย . ทำการ preprocess ค่าของแต่ละตัวอย่าง | ทำการแปลงคำตอบให้อยู่ในรูปของ vector | . &#3607;&#3635;&#3585;&#3634;&#3619; Preprocess &#3619;&#3641;&#3611;&#3616;&#3634;&#3614; . ตอนนี้ค่าที่อธิบายถึงรูปภาพเรามีค่าเป็นยังไงนะ . จะเห็นว่ามีค่าตั้งแต่ 0 จนถึง 253 (จริงๆค่าที่เป็นไปได้มากสุดคือ 255 เนื่องจากข้อมูลเก็บเป็น unsign 8 bits) แล้วแบบนี้หมายความว่ายังไง เวลา program เราเรียนรู้ กลุ่มตัวแปรที่มีค่ามากจะเป็นตัวแปรที่มีอำนาจในการตัดสินให้คำตอบ ทั้งที่ตัวแปรอื่นๆที่ค่าน้อยก็มีโอกาสที่เป็นตัวแปรที่มีความสำคัญต่อการผลิตคำตอบ ซึ่งมีผลกับการเรียนรู้ ดังนั้นเราต้องนำค่าตัวแปรต่างๆที่ใช้อธิบายรูปภาพมาทำการ normalization โดยในกรณีนี้คือนำค่าทั้งหมดมาหารด้วย 255 ซึ่งการทำอย่างนี้นอกจากจะทำให้ความสำคัญของแต่ละตัวแปรมีน้ำหนักพอๆกันแล้ว ยังช่วยให้เรียนรู้ได้เร็วขึ้นด้วย (จินตนาการว่ากราฟแสดงความสัมพันธ์ระหว่าง error และ weight 2 ตัว ที่การส่ายไปส่ายมาแทนที่จะตรงไปยังจุดที่เป็นเป้าหมาย) . เดี๋ยวเรามาทำการ normalization รูปภาพทั้งหมดกันทั้งใน training และ testing set . x_train = x_train / 255 x_train = x_train.reshape((x_train.shape[0], x_train.shape[1] * x_train.shape[2]))[11000:12000] x_test = x_test / 255 x_test = x_test.reshape((x_test.shape[0], x_test.shape[1] * x_test.shape[2])) print(f&quot;มาดูข้อมูลรูปภาพใน training set กัน :{x_train.shape}&quot;) print(f&quot;มาดูข้อมูลรูปภาพใน testing set กัน :{x_test.shape}&quot;) . มาดูข้อมูลรูปภาพใน training set กัน :(1000, 784) มาดูข้อมูลรูปภาพใน testing set กัน :(10000, 784) . จะเห็นว่าเราทำการหารด้วย 255 เพื่อทำให้ตัวแปรต่างๆในแต่ละรูปภาพมีความสำคัญต่อคำตอบพอๆกัน นอกจากนี้ถ้าจำได้ neural netwrok program จะรับ inputs เข้ามาเป็น 1D list หรือ vector เนื่องจากรูปภาพเราถูกนำเสนอเป็น 28 x 28 เราทำการแปลงเป็น vector โดยการใช้ reshape method ซึ่งเป็นฟังก์ชันที่ใช้สำหรับปรับ representation ของ array ในกรณีนี้เราปรับจากการนำเสนอในรูปแบบ metric เป็น vector โดยถ้าสังเกตใน training set จาก 60,000 ตัวอย่าง ในกรณีนี้ผมหยิบมาแค่ 1,000 ตัวอย่างสำหรับใช้สร้าง neural network program (เพ่ือความเร็ว)ถ้าต้องการใช้ตัวอย่างทั้งหมดก็ทำการลบในส่วนการเลือกตัวอย่างออกไปนะครับ ส่วน testing set ยังคงจำนวนตัวอย่างไว้เท่าเดิม . &#3607;&#3635;&#3652;&#3617;&#3648;&#3619;&#3634;&#3605;&#3657;&#3629;&#3591;&#3607;&#3635;&#3585;&#3634;&#3619;&#3649;&#3611;&#3621;&#3591;&#3588;&#3635;&#3605;&#3629;&#3610;&#3651;&#3627;&#3657;&#3629;&#3618;&#3641;&#3656;&#3651;&#3609;&#3619;&#3641;&#3611;&#3586;&#3629;&#3591; Vector ? . สังเกตว่าถ้าปัญหาเรามีคำตอบเดียวเราจะแทนที่ด้วย output node แค่ node เดียวแต่ถ้าเรามีหลายคำตอบเราจะมี output nodes มากกว่า 1 node ทำไมเราไม่ใช้ node เดียวแล้วให้ค่าคำตอบเป็น 0 - 9 ละ? เนื่องจากถ้าเราทำแบบนั้น เท่ากับเราบอก program เราด้วยว่าความสัมพันธ์ระหว่างคำตอบของเราจะมี semantic relationship นั่นคือ คำตอบที่เป็นเลข 8 มีค่ามากกว่า เลข 7 ซึ่งความจริงถ้ามองในมุมตัวเลขก็ถูก และนอกจากนี้คำตอบที่เราได้ยังมีโอกาสที่จะเป็นค่าระหว่างคำตอบจริงๆที่เราต้องการ เช่นคำตอบออกมาเป็น 7.5 แต่คราวนี้ถ้ามองใบริบทที่เรากำลังทำอยู่ เราต้องการแค่อยากรู้ว่าจากรูปที่ได้มาตัว program ต้องบอกเราให้ได้ว่ามันเป็นเลขอะไรโดยไม่สนว่าเลขนั้นจะมีค่ากว่าอีกเลขไหม . Note: คำตอบในกรณี MNIST เป็น discrete value และไม่มีความสัมพันธ์กันระหว่าง value . ซึ่งจะนำไปสู่เรื่องของการเลือกแสดงคำตอบของ output layer โดยถ้าคำตอบเราเป็น numeric หรือเป็น continuous value เราก็สามารถนำเสนอ output layer ได้ด้วย node เดียวให้คำตอบเป็น numeric ในช่วงคำตอบที่สนใจ เช่น [-1, 1] ใช้สามารถ tanh เป็น activation function หรือถ้าไม่มีการกำหนดขอบเขตตายตัวก็ไม่ต้องมี activation function แต่ถ้าคำตอบที่เราต้องการเป็น category หรือ predefined set of classes จะทำให้ output layer เราต้องนำเสนอด้วย nodes ที่มีจำนวนเท่ากับ classes โดยในแต่ละ node จะให้ค่าออกเป็นความน่าจะเป็นว่ามีโอกาสเป็น class นี้หรือเปล่า โดยจะเป็น unrelated probability (แต่ละ node มีความน่าจะเป็นของตัวเองไม่เกี่ยวข้องกัน เช่น sigmoid function) หรือ related probability (แต่ละ node ใน layer มีความน่าจะเป็นที่เกี่ยวข้องกัน เช่น การใช้ softmax function) . สรุปคือคำตอบของปัญหา MNIST เป็นแบบ discrete value และ order ไม่สำคัญเนื่องจากไม่มีความสัมพันธ์ระหว่าง class ดังนั้นเราจะทำการแปลงจากข้อมูลปัจจุบันที่แสดงคำตอบเป็นค่าๆเดียว {0, 1, 2, 3, 4, 5, 6, 7, 8, 9} ให้เป็น vector ที่แต่ละ node คือตัวแทนว่าเป็น node ที่บ่งบอกถึงเลขอะไร เช่น node ที่ 0 เป็นตัวแทนของเลข 0 ส่วน node ที่ 8 เป็นตัวแทนของเลข 8 โดยค่าในแต่ละ node บ่งบอกถึงความน่าจะเป็นที่จะเป็นเลขนั้น ขอยกตัวอย่างเช่นเลข 8 เมื่อเราทำการแปลงเป็น vector จะได้เป็น [0, 0, 0, 0, 0, 0, 0, 0, 1, 0] จะเห็นได้ว่า node ที่ไม่ได้เป็นคำตอบจะถูกแทนที่ค่าด้วย 0 ส่วน node ที่เป็นคำตอบจะถูกแทนที่ค่าด้วย 1 ถ้าลองแปลงตัวเลขอื่นๆด้วยจะทำให้เราเห็นรูปแบบบางอย่างนั่นคือตัวเลขที่ไม่ใช่คำตอบจะเป็น 0 ทั้งหมด และตัวเลขที่เป็นคำตอบจะเป็น 1 และ! เนื่องจากคำตอบเรามีแค่คำตอบเดียว node ที่เป็น 1 เลยมีแค่ node เดียวที่เหลือเป็น 0 เราเลยเรียกการแปลงข้อมูลจาก numeric เป็น vector ว่าการทำ one hot encoder แน่นอว่าเรานำเสนอข้อมูลอบบนี้ในกรณีที่ปัญหาเราเป็นแบบ multiclass problem นั่นคือมีแค่คำตอบเดียวที่ถูกต้องจากทั้งหมด แต่... ถ้าปัญหาเราเป็น multilabel multiclass หรือจากคำตอบทั้งหมดสามารถตอบได้มากกว่า 1 คำตอบ node ที่เป็น 1 ก็จะมีมากกว่า 1 node . โอเค เรามาลองทำการ one hot encoder กันดีกว่า . y_train_one_hot = np.zeros(shape=(y_train.shape[0], 10)) for i in range(y_train_one_hot.shape[0]): y_train_one_hot[i][y_train[i]] = 1 y_train = y_train_one_hot[11000:12000] print(f&quot;มาดูข้อมูลคำตอบใน training set กัน :{y_train.shape}&quot;) print(f&quot;คำตอบของตัวอย่างแรกคือ {y_train[0]} นั่นคือเลข 5 นั่นเอง&quot;) . มาดูข้อมูลคำตอบใน training set กัน :(1000, 10) คำตอบของตัวอย่างแรกคือ [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.] นั่นคือเลข 5 นั่นเอง . แรกเริ่มเราทำการสร้างโครงสร้างของ vectors ราออกมาก่อน(metric เมื่อนำเอา vectors ทั้งหมดมารวมกันเป็นคลังข้อมูลเกี่ยวกับคำตอบ)นั้นคือกำหนดให้แต่ละ vector ที่เป็นตัวแทนของคำตอบในแต่ละตัวอย่างให้ทุก nodes เป็น 0 หมด หลังจากนั้นเราจะไล่แทนค่า 1 คำไปยัง node ที่เป็นตัวแทนคำจอบของแต่ละตัวอย่าง (ในกรณีนี้ vector นึงจะมี node เดียวที่เป็น 0 เนื่องจากคำตอบที่ถูกต้องมีเพียงคำตอบเดียว) เรามาทำแบบเดียวกันกับคำตอบ testing set กันดูบ้าง . y_test_one_hot = np.zeros(shape=(y_test.shape[0], 10)) for i in range(y_test_one_hot.shape[0]): y_test_one_hot[i][y_test[i]] = 1 y_test = y_test_one_hot print(f&quot;มาดูข้อมูลคำตอบใน testing set กัน :{y_test.shape}&quot;) print(f&quot;คำตอบของตัวอย่างแรกคือ {y_test[0]}&quot;) . มาดูข้อมูลคำตอบใน testing set กัน :(10000, 10) คำตอบของตัวอย่างแรกคือ [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.] . จะเห็นได้ว่าเราเปลี่ยนคำตอบที่แสดงในรูปแบบ numeric ให้กลายเป็น one hot vector ได้สำเร็จ . &#3585;&#3656;&#3629;&#3609;&#3617;&#3634;&#3648;&#3619;&#3636;&#3656;&#3617;&#3607;&#3635;&#3585;&#3634;&#3619;&#3626;&#3619;&#3657;&#3634;&#3591; Neural Network program &#3617;&#3634;&#3619;&#3641;&#3657;&#3592;&#3633;&#3585; Activation function &#3585;&#3633;&#3609;&#3585;&#3656;&#3629;&#3609; . ก่อนอื่นในแต่ละ layer (ที่ไม่ใช่ output layer) เรายังไม่มีการใช้ activation function ในรอบนี้เราจะมาใช้กัน โดย function ที่เราจะใช้ก็คือ relu นั่นเอง ฟังก์ชันมีความง่ายมากนั่นคือ ถ้าค่ามากกว่า 0 ให้ทำการคงคำตอบค่าเดิมเอาไว้ แต่ถ้าค่าน้อยกว่าหรือเท่ากับ 0 ให้ทำการแปลงคำตอบให้กลายเป็น 0 . Warning: ทำไมต้อง activation function หรือให้เฉพาะเจาะจงทำไมต้อง non linear activation function เนื่องจากถ้าเราไม่มี function นี้ ตัวโปรแกรมเราถึงแม้จะเป็น neural network ที่มี 10 layers ก็ไม่ช่วยอะไรเนื่องจาก neural network แค่ 2 layers ก็สามารถให้คำตอบเดียวกับ neural network ที่มี 10 layers ลองคิดในแง่ของ correlation ว่าถ้า weights คือ correlation ระหว่าง layers โดยจุดประสงค์หลักของ program ในการเรียนรู้คือการหา correlation ระหว่าง inputs และ outputs ถ้าเราไม่มี non linear activation function จะทำให้ correlation ในแต่ละช่วงของตัวโปรแกรม (ในกรณีนี้เรามี hidden layer) สุดท้ายก็ขึ้นอยู่กับ correlation ที่มีกับ inputs layer (นี่แหละ! ที่ทำให้ถึงแม้เรามี layer เยอะแค่ไหนก็ตาม คำตอบสุดท้ายก็สามารถผลิตได้ด้วย program ที่มีแค่ input และ output layer) แต่ถ้าเรามีการใช้ activation function นั้นเท่ากับว่าในแต่ละ layer มีสิทธิ์ที่จะสร้าง correlation ของตัวเองขึ้นมา โดยไม่ได้ขึ้นอยู่กับแค่ฝั่งของ input layer ทำให้เราสามารถสร้าง correlation ที่ซับซ้อน และสุดท้ายก็สร้าง indirect correlation ได้ โดย correlation จาก input layer เป็นแค่ส่วนหนึ่งของ correlation ทั้งหมด ที่ตัวโปรแกรมพยายามสร้างขึ้นมา (ไม่เหมือนกับการใช้ correlation โดยตรงระหว่าง input layer และ output layer) . เหตุผลว่าทำไมต้อง activation function ผมขอลองใช้การเปรียบเทียบดูนะครับ จินตนาการดูครับว่า เรามีสร้อยคออันนึงเล็กๆแต่อยากกจะเซอไพส์แฟน แต่ในตอนนี้มีแค่กระดาษ A4 จำนวนนึง (หากล้องของขวัญไม่ทันแล้ว) เราก็เลยคิดว่างั้นเอาเลยละกัน เราเอา A4 ห่อสร้อยเอาไว้หลายๆชั้นและมีการขยัมให้เป็นก้อนกลมๆ พอเราส่งให้แฟน แฟนก็ตอบว่า &quot;มันคืออะไรเนี่ย&quot; แฟนมี 2 ตัวเลือกคือ . คลี่ | ดีด | . โดยการคลี่หนึ่ง ครั้งเรามองเป็น 1 step และการดีดหนึ่งครั้งก็มองเป็น 1 step ดุแล้วปัญหานี้ก็เป็นปัญหาที่ซับซ้อนพอควรเพราะเราต้องคลี่ด้วยมุม, แรงและทิศทางที่ไม่มีกำหดตายตัวจนกระทั้งเจอสสร้อย ทุกครั้งที่เราคลี่เราเปลี่ยนแปลง representation ทุกครั้ง เราคลี่ไปเรื่อยๆ แล้วหยุดคิดแปปนึงว่าจาก representation ปัจจุบันของก้อนกระดาษที่ห่อสร้อยกับก้อนกระดาษที่ผ่านการคลี่แค่ครั้งเดียวก่อนหน้านี้ จะเห็นว่าเรามาไกลแค่ไหนและการคลี่ของเราเมื่อมองมันเป็น list ของ actions มีความซับซ้อนเมื่อเทียบกับตอนเราพึ่งจะคลี่ไปรอบเดียว แต่เราไม่รู้สึกถึงความซับซ้อนเพราะแต่ละ step เราทำแค่ขั้นตอนง่ายๆคือการคลี่ แต่ถ้าเรายังไม่เริ่มคลี่แล้วต้องการทำการคลี่ทีเดียวเพื่อให้ได้ผลลัพธ์เหมือนกับที่เราคลี่ไปแล้ว 25 ครั้ง มันจะเป็นคู่มือขั้นตอนที่ซับซ้อนมากในการทำทีเดียว จะเห็นว่าแต่ละ step ก็เหมือนแต่ละ layer ของ neural network program และการคลี่ก็คือ non linear actibation function ซึ่ง function นี้ผลลัพธ์คือการสะสมความซับซ้อนขึ้นทีละนิด . แต่ถ้าเราใช้ linear activation function หรือไม่ใช้เลยละ มันก็จะเปรียบได้กับการดีดก้อนกระดาษที่ห่อสร้อย representation เราเปลี่ยนนั่นคือก้อนมีการขยับและหยุดโดยทำมุมต่างจากตอนแรก แต่การดีด 25 ครั้งก็ไม่ทำให้เราใกล้กับคำตอบรวมถึง ผลลัพธ์จากการดีด 25 ครั้ง บางทีเราอาจจะสามารถทำได้ด้วยการดีดเพียงครั้งเดียว และที่โชคร้ายคือการดีดไม่ซับซ้อนพอที่จะพาเราไปสู่คำตอบได้ เปรียบได้กับ neural network ที่มีหลาย layer ก็จริงแต่สุดท้ายผลผลิตก็สามารถถูกผลิตได้ด้วย program ที่มี layer เดียว นอกจากนี้ยังไม่มีความซับซ้อนพอที่จะผลิตคำตอบที่เหมาะสมอีกด้วย . &#3588;&#3640;&#3603;&#3626;&#3617;&#3610;&#3633;&#3605;&#3636;&#3586;&#3629;&#3591; Activation function . ผมขอแบ่งคุณสมบัติที่ควรมีของ activation function ออกมาเป็น 4 คุณสมบัติ . 1. Activation functions &#3605;&#3657;&#3629;&#3591;&#3648;&#3611;&#3655;&#3609; Continuous function . นั่นคือทุก input (infinite domain) ของเราที่ใส่เข้าไปใน function จะต้องมีคำตอบออกมาทั้งหมด เราไม่ควรที่จะใส่ input เข้าไปแล้วไม่มี output ออกมา . 2. Activation functions &#3607;&#3637;&#3656;&#3604;&#3637; &#3592;&#3632;&#3605;&#3657;&#3629;&#3591;&#3652;&#3617;&#3656;&#3648;&#3611;&#3621;&#3637;&#3656;&#3618;&#3609;&#3649;&#3611;&#3621;&#3591;&#3607;&#3636;&#3624;&#3607;&#3634;&#3591; . มันหมายความว่ายังไงกันนะ ลองคิดถึงพวกกราฟยกกำลัง เช่น ยกกำลัง 2 . x = np.arange(-5,5,0.1) y = x ** 2 let_show.plot(x, y) . [&lt;matplotlib.lines.Line2D at 0x7fa2c0a016d0&gt;] . จะเห็นว่าคำตอบที่ได้มีการเปลี่ยนทิศทางจากลบเป็นบวก ถ้าเราเพิ่มค่าแนวแกน x เพิ่มขึ้นเรื่อยๆ แบบนี้แสดงว่าถ้า x เราคือ weight และ y คือคำตอบ คำตอบที่ถูกต้องสามารถหาได้จากการปรับ x ไปด้านซ้ายหรือขวา ตอนนี้แหละเราจะเกิด 2 มุมมอง . มุมมองแรก เอ้ยมันดีนะเรามีโอกาสที่จะหาคำตอบที่ถูกต้องเจอมากขึ้น เจ๋งเลย | มุมมองที่สอง แย่แล้วคำตอบที่ถูกต้องสามารถหาได้จากการเลื่อน x ไปทางซ้ายหรือ ขวา แล้วเราควรจะเลื่อนไปด้านไหนดี? | . ซึ่งพอมามองในมุมมองของ neural network program แล้วหรือเฉพาะเจาจง optmization alogorithm มุมมองที่สองมีความสำคัญและส่งผลต่อการเรียนรู้มากกว่า ดังนั้นเราควรจะเลือก functions ที่ไม่เปลี่ยนทิศทาง . 3. Activation functions &#3648;&#3611;&#3655;&#3609; Non Linear functions . ตามเหตุผลที่อธิบายไปก่อนหน้าที่ถ้าเป็น non linear functions ยิ่ง steps ในโปรแกรมเยอะก็หมายถึง program มีความซับซ้อนมากขึ้น และสามารถแก้ไขปัญหาที่ซับซ้อนได้ ถ้ามองในมุม correlation คือ hidden layer สามารถสร้างปรากฏการณ์ selective correlation ได้ ส่งผลให้แต่ละ layer สร้าง correlation ของตัวเองได้ (ทำให้แต่ละ layer เปรียบเสมือน representation ใหม่ของข้อมูลของเรา) และสุดท้ายส่งผลให้ output layer ไม่ได้ขึ้นอยู่กับแค่ correlation จาก input layer เพียงอย่างเดียว แต่เป็น correlation โดยรวมจาก layers ก่อนหน้าทั้งหมด ซึ่งมีความซับซ้อน . 4. Activation functions &#3605;&#3657;&#3629;&#3591;&#3626;&#3634;&#3617;&#3634;&#3619;&#3606;&#3588;&#3635;&#3609;&#3623;&#3603;&#3652;&#3604;&#3657;&#3651;&#3609;&#3648;&#3594;&#3636;&#3591;&#3651;&#3594;&#3657;&#3591;&#3634;&#3609;&#3592;&#3619;&#3636;&#3591; &#3619;&#3623;&#3617;&#3606;&#3638;&#3591; derivative &#3586;&#3629;&#3591;&#3605;&#3633;&#3623; function &#3648;&#3629;&#3591;&#3604;&#3657;&#3623;&#3618; . ง่ายๆก็คือสามารถคำนวณได้ และต้องเร็ว เนื่องจาก activation functions จะต้องถูกเรียกบ่อยมากๆ . &#3648;&#3619;&#3634;&#3617;&#3634;&#3604;&#3641; Activation functions &#3607;&#3637;&#3656;&#3606;&#3641;&#3585;&#3651;&#3594;&#3657;&#3651;&#3609; Hidden layer &#3585;&#3633;&#3609; . functions ที่ใช้กันผมจะขอยกตัวอย่างมา 3 functions . 1. Sigmoid function . จะทำการให้คำตอบระหว่าง [0, 1] ซึ่งเหมาะมากในการใช้อธิบายความน่าจะเป็นของ node โดย 1 ก็คือมีโอกาส 100% นั่นทำให้ functions นี้ถูกนำไปใช้ทั้งใน hidden และ output layer . def sigmoid(x): output = 1 / (1 + np.exp(-x)) return output def derivative_of_sigmoid(output): derivative_output = output * (1 - output) return derivative_output . 2. tanh function . ในส่วนของ tanh จะให้คำตอบระหว่าง [-1, 1] เนื่องจากมีโอกาสให้คำตอบเป็นจำนวนติดลบด้วย ทำให้ในหลายปัญหามีประโยชน์กว่า sigmoid การทำ weight sum คือการดูว่า inputs ของเราเป็นไปในทิศทางเดียวกับ correlation ที่มีสำหรับ node ที่สนใจไหม (การทำ weight sum มองเป็นการหา similarity หรือแนวโน้มที่ไปทางเดียวกันกับความสัมพันธ์) ถ้าคำตอบเป็นลบแสดงว่ายังมีความสัมพันธ์กันอยู่ระหว่าง input กับ output node แต่เป็นความสัมพันธ์ที่ input มีความตรงกันข้ามกับ output ซึ่ง tanh สามารถอธิบายตรงนี้ได้ แต่ sigmoid จะบอกคำตอบว่าเป็น 0 ซึ่งบอกว่าค่า input ที่เข้ามาปัจจุบันไม่มีความสัมพันธ์กับ output เพราะ sigmoid function ทำให้ node บอกได้แค่ว่ามีความสัมพันธ์ไหม หรือไม่มี . def tanh(x): output = np.tanh(x) return output def derivative_of_tanh(output): derivative_output = 1 - (output ** 2) return derivative_output . 3.relu function . จะให้ผลลัพธ์เป็นค่าเดิมเมื่อค่ามากกว่า 0 แต่ถ้าค่าน้อยกว่าหรือเท่ากับ 0 จะให้ค่าคำตอบที่เป็น 0 เท่านั้น ผลกระทบจะเหมือน sigmoid เลยนั่นคือจะบอกได้แค่จาก input ที่ได้มามีความสัมพันธ์ไหม หรือไม่มี แต่ที่ต่างคือตัวสมการ sigmoid จะให้ค่า derivative ที่สูงเมื่อ input เข้าใกล้ 0 แต่เมื่อคำตอบที่ได้จาก sigmoid เข้าใกล้ 1 หรือ 0 จะทำให้ค่า derivative เข้าใกล้ 0 ซึ่งส่งผลให้เกิดความ Stickness ซึ่งส่งผลดีในกรณีที่มีมี noise เข้ามาในช่วงที่ weights เราจุดที่มีความมั่นใจในการสร้างคำตอบแล้ว เช่น คำตอบเข้าใกล้ 0 หรือ 1 การที่มี noise ทำให้เกิด error ก็จะไม่รบกวนคำตอบที่ program สร้างขึ้นมา แต่ แต่... ก็มีผลเสียเหมือนกันคือเมื่อ program เรียนรู้แล้วยังไม่เข้าสู่จุดที่เข้าใจบทเรียน แต่ node ของเราบาง node ไปถึงจุด stickness เรียบร้อยแล้ว (ทั้งที่จริงยังต้องปรับขึ้นหรือลงอีก) ส่งผลทำให้เกิดความยากในการเรียนรู้ อาจถึงขั้นต้อง reset เพื่อเรียนรู้ใหม่ ดังนั้น relu จะไม่มีในเรื่องของ stickness เนื่องจากเมื่อค่ามากกว่า 0 ค่า derivative จะมีค่าเป็น 1 และเมื่อน้อยกว่า 0 ค่า derivative จะมีค่าเป็น 0 . def relu(x): output = (x &gt; 0) * x return output def derivative_of_relu(output): derivative_output = output &gt; 0 return derivative_output . ความจริงในส่วนของ derivative function ค่า input จะต้องเป็น x ไม่ใช่ output แต่เพื่อความง่ายในการคำนวณเมื่อสร้าง neural network program เราจะใช้แบบนี้ในการคำนวณ (ไม่ส่งผลต่อคำตอบ เพราะจำนวนติดลบก็ถูกแปลงเป็น 0 และ ค่า 0 ใส่คำไปใน derivative function ของ relu ก็ให้คำตอบเป็น 0 อยู่ดี) . &#3648;&#3619;&#3634;&#3617;&#3634;&#3604;&#3641; Activation functions &#3607;&#3637;&#3656;&#3606;&#3641;&#3585;&#3651;&#3594;&#3657;&#3651;&#3609; output layer &#3585;&#3633;&#3609; . จะขอแบ่งการใช้ activation จากปัญหาออกเป็น 3 รูปแบบนะครับ . 1. &#3605;&#3657;&#3629;&#3591;&#3585;&#3634;&#3619;&#3588;&#3635;&#3605;&#3629;&#3610;&#3607;&#3637;&#3656;&#3648;&#3611;&#3655;&#3609; Numeric . ในที่นี้เราสามารถปล่อยให้ node ไม่ต้องมี activation functions ได้เลย หรือถ้าเราต้องการจำกัดขอบเขตของคำตอบก็ทำการใช้ sigmoid หรือ tanh ได้ . 2. &#3617;&#3637;&#3588;&#3635;&#3605;&#3629;&#3610;&#3627;&#3621;&#3634;&#3618;&#3588;&#3635;&#3605;&#3629;&#3610;&#3649;&#3621;&#3632;&#3617;&#3637;&#3588;&#3635;&#3605;&#3629;&#3610;&#3607;&#3637;&#3656;&#3606;&#3641;&#3585;&#3605;&#3657;&#3629;&#3591;&#3617;&#3634;&#3585;&#3585;&#3623;&#3656;&#3634; 1 &#3588;&#3635;&#3605;&#3629;&#3610; . ในกรณีนี้ที่มีหลายคำตอบแสดงว่าเราแทนที่คำตอบด้วย vector โดยแต่ละ element ใน vector จะเป็นตัวแทนของคำตอบนั้น และเนื่องจากมีคำตอบที่ถูกต้องมากกว่า 1 คำตอบ เราเลยให้แต่ละ node มีความน่าจะเป็นของตัวเอง ถ้า node ไหนมีความน่าจะเป็นมากกว่า threshold ที่กำหนดก็จะเลือก node นั้นเป็นคำตอบ หมายความว่าแต่ละ node เราจะใช้ sigmoid เป็น activation functionถ้า . 3. &#3617;&#3637;&#3588;&#3635;&#3605;&#3629;&#3610;&#3627;&#3621;&#3634;&#3618;&#3588;&#3635;&#3605;&#3629;&#3610;&#3649;&#3621;&#3632;&#3617;&#3637;&#3588;&#3635;&#3605;&#3629;&#3610;&#3607;&#3637;&#3656;&#3606;&#3641;&#3585;&#3605;&#3657;&#3629;&#3591;&#3648;&#3614;&#3637;&#3618;&#3591;&#3588;&#3635;&#3605;&#3629;&#3610;&#3648;&#3604;&#3637;&#3618;&#3623; . ถ้าเราใช้ sigmoid แล้วทำการสร้าง neural network program ให้เกิดการเรียนรู้ จะเหมือนเป็นการบอก program ว่า &quot;นี่ๆเจ้า program ใน out layer แต่ละ node ช่วยทำให้ค่าอื่นๆที่ไม่ใช่คำตอบที่ถูกต้องเป็น 0 และให้ node ที่เป็นคำตอบี่ถูกต้องเป็น 1&quot; สมมุติเรามี 3 คำตอบ ได้แก่ [0.2, 0.3, 1] และคำตอบที่ถูกต้องคือคำตอบที่สาม จะเห็นได้ว่า program เราตอบถุกและมั่นใจมากๆ แต่การเรียนรู้ยังไม่หยุดเนื่องจาก node ที่เหลือยังไม่เป็น 0 ใช่แล้วเป้าหมายของ sigmoid ไม่ใช่แค่ขอคำจอบที่ถูกต้องเป็น 1 แต่คำตอบที่ผิดต้องเป็น 0 ด้วย! . ดังนั้นจากตรงนี้เราเลยต้องมีการปรับปรุงให้มีประสิทธิภาพมากขึ้นนั่นคือเราโฟกัสไปแค่ node ที่เป็นคำตอบที่ถูกแล้วพยายามปรับความน่าจะเป็นให้มากขึ้นเรื่อยๆ ส่วน nodes ที่เหลือจะมีการลดลงของความน่าจะเป็นแบบอัตโนมัติ เอ๊ะทำไมกันนะ? เพราะว่าทุก nodes ใน output vector ทำการแชร์ความน่าจะเป็นกัน (หรือมีความน่าจะเป็นแค่อันเดียว ต่างจาก sigmoid ที่ความน่าจะเป็นจะแยกไปเป็นของแต่ละ node) ทำให้การใช้ sigmoid เป็นการบอกว่า &quot;เฮ้ คำตอบไหนเป็นคำตอบที่ถูกต้องที่สุด ก้ปรับให้คำตอบนั้นค่าความน่าจะเป็นออกมามากที่สุด node อื่นที่ไม่ใช่คำตอบก็จะมีความน่าจะเป็นที่น้อยลงเองอัตโนมัติ&quot; . แล้วคำนวณยังไงนะ sigmoid ให้มองเป็น 3 ขั้นตอนง่าย . ทำการ weight sum ระหว่าง input vector และ weight vector (ปกติที่เราทำกันมา) | ทำการ คำนวณ exponential function โดยที่เลขฐานเป็น e | นำค่าแต่ละ node มาตั้งและหารด้วย ค่าของ node ทั้งหมดรวมกัน (หาความน่าจะเป็นของแต่ละ node) | def softmax(x): expoential_output = np.exp(x) output = expoential_output / np.sum(expoential_output) . &#3617;&#3634;&#3648;&#3619;&#3636;&#3656;&#3617;&#3626;&#3619;&#3657;&#3634;&#3591; Neural Network program &#3626;&#3635;&#3627;&#3619;&#3633;&#3610; Dataset &#3585;&#3633;&#3609;&#3604;&#3637;&#3585;&#3623;&#3656;&#3634; . alpha, iterations, hidden_layer1 = 0.01, 500, 32 . เริ่มแรกมากำหนด learning rate กันก่อนให้เท่ากับ 0.003 (ค่ามากน้อยขึ้นอยู่กับข้อมูลและโครงสร้าง program เรายิ่งค่ามากยิ่งมีการปับ weight มากในครั้งเดียว และยิ่งค่าน้อยก็ยิ่งปรับ weight น้อย มีผลกับเวลาในการเรียนรู้) ต่อมาคือ iteration (epochs) ใช้บอกว่าเราจะให้โปรแกรมเห็น dataset ทุกตัวอย่างทั้งหมดกี่ครั้ง และสุดท้ายจำนวน node ใน hidden layer . weight_0_1 = 0.2 * np.random.random(size=(x_train.shape[1], hidden_layer1)) - 0.1 weight_1_2 = 0.2 * np.random.random(size=(hidden_layer1, 10)) - 0.1 . weight_0_1 คือ weight ระหว่าง layer 0 (input layer) กับ layer 1 (hidden layer 1) | weight_1_2 คือ weight ระหว่าง layer 1 (hidden layer 1) กับ layer 2 (output layer) | . โดยเราทำการเลื่อนค่าให้มีค่า mean อยู่ที่ - 0.1 และ มีการกะจายของข้อมูลเป็น 0.2 (scale) . for j in range(iterations): error, correct_count = 0, 0 for i in range(x_train.shape[0]): layer_0 = x_train[i:i+1] layer_1 = relu(layer_0.dot(weight_0_1)) layer_2 = layer_1.dot(weight_1_2) error += np.sum((layer_2 - y_train[i:i+1]) ** 2) correct_count += int(np.argmax(layer_2) == np.argmax(y_train[i:i+1])) layer_2_delta = layer_2 - y_train[i:i+1] layer_1_delta = derivative_of_relu(layer_1) * (layer_2_delta.dot(weight_1_2.T)) weight_0_1 -= alpha * layer_0.T.dot(layer_1_delta) weight_1_2 -= alpha * layer_1.T.dot(layer_2_delta) print(f&#39;Error: {error / x_train.shape[0]}&#39;) print(f&#39;Accuracy: {correct_count / x_train.shape[0]}&#39;) . Error: 0.002805354217390215 Accuracy: 0.998 . สังเกตว่าเรามีการปรับ weights ในทุกๆตัวอย่างของ training set (1,000 ตัวอย่าง) ดังนั้นเราจะมีการปรับ weights ทั้งหมด 1,000 x 350 (iteration)  เป็น 350,000 ครั้ง! แต่ว่าการทำแบบนี้การปรับ weights แต่ละครั้งด้วยตัวอย่างเดียวอาจทำให้บางครั้งของการปรับ weights เกิด noise ได้ทำให้ weights เดินผิดเพี้ยนไป แต่โดยรวม weights แต่ละค่าก็พยายามมุ่งเข้าหาค่าของ weights ที่ควรจะเป็นถ้าเราลองวาดเป็นกราฟการเดินทางก็จะมี noise เกิดขึ้นบ้างแต่ trend โดยรวมก็ยังเหมือนเดิม จริงๆการปรับ weights สามารถทำได้ 3 แบบ . stochastic gradient descent | full gradient descent | batch gradient descent | โดยเกิดจากว่าแรกเริ่มใช้ full gradient descent แต่เมื่อคลังข้อมูลเรามีขนาดใหญ่มากขึ้นเราไม่สามารถใส่ข้อมูลทั้งหมดใน memory รวมถึงการอัพเดท weights ครั้งหนึ่งใช้เวลานานมาก เช่นเมื่อต้องสร้าง program จาก ImageNet dataset ซึ่งมีภาพหลักล้านรูป ถ้าเรารอให้ครบทั้ง dataset แบะอัพเดททีหนึ่งเราจะใช้เวลาในการ training นานมากๆ ดังนั้นจึงเกิดแนวคิดว่าแล้วทำไมเราไม่ใส่ตัวอย่างหนึ่งและปรับ weights หนึ่งที ซึ่งจะทำให้เรามีการปรับ weights ได้หลายครั้งมากต่อการใช้ dataset ทั้งหมด 1 รอบ แต่อย่างที่บอกคือ เราอัพเดทได้เร็วก็จริงแต่การอัพเดทแต่ละครั้งมีโอกาสเป็น noise ดังนั้นเราเลยอยู่กึ่งกลางละกันโดยการใช้ batch gradient descent นั่นคือเรามีโอกาสอัพเดทมากกว่าการใช้ full gradient descent  และการอัพเดทแต่ละครั้งก็มีโอกาสเกิด noise น้อยกว่าและมีโอกาสมุ่งเข้าสู่ค่า weights ที่เป็นคำตอบมากกว่า เนื่องจากมีการเฉลี่ยกันของหลายๆตัวอย่างถึงแม้จะไม่ได้แนวโน้มการอัพเดทที่ดีเท่า full dataset แต่ก็เป็นแนวโน้มการอัพเดทที่ดีกว่าการอัพเดทจากทีละหนึ่งตัวอย่าง (หมายความว่าอาศัยจำนวนการอัพเดทน้อยกว่าแบบ stochastic gradient descent อีกด้วย) ยิ่งไปกว่านั้นการทำแบบ batch ยังเป็นการใช้ optimization library สำหรับ linear algebra อย่างคุ้มค่าเมื่อเราทำการอัพเดท weights ทั้งหมด 10 iterations แบบ batch จะมีความเร็วกว่าแบบ stochastic gradient descent อีกด้วย . จะเห็นว่าผลลัพธ์ออกมาเป็น accuracy 99.9% Wow! แต่ แต่... อย่าลืมว่าอันนี้เราทพสอบกับคลังข้อมูลที่ program เราเรียนรู้โดยตรง เดี๋ยวเราลองมาทดสอบกับคลังข้อมูลที่ program ยังไม่เคยเห็นมาก่อน . error, correct_count = 0.0, 0 for i in range(x_test.shape[0]): layer_0 = x_test[i:i+1] layer_1 = relu(layer_0.dot(weight_0_1)) layer_2 = layer_1.dot(weight_1_2) error += np.sum((layer_2 - y_test[i:i+1]) ** 2) correct_count += int(np.argmax(layer_2) == np.argmax(y_test[i:i+1])) print(f&#39;Error: {error / float(x_test.shape[0])}&#39;) print(f&#39;Accuracy: {correct_count / x_test.shape[0]}&#39;) . Error: 0.40306746534485255 Accuracy: 0.8093 . จะเห็นว่าเมื่อเราทดสอบกับ training set เราได้ 99.9% แต่พอมาทดสอบกับ testing set กับได้ 82.71% ซึ่งต่างกันพอสมควร งั้นแปลว่า program เรายังเอามาใช้กับข้อมูลที่ไม่เคยเห็นได้ดีพอทำไมกันนะ? . มีหลากหลาย weights configuration ที่ทำให้ค่า error ต่ำและ program ออกมาดีเมื่อทดสอบกับ training set แต่เป้าหมายเราคือการหา weights ที่สามารถทำให้ทดสอบกับข้อมูลที่ไม่เคยเห็นและได้คำตอบที่ถุกต้องนั่นคือเมื่อทดสอบกับ testing set จะต้องได้ผลััพธืออกมาดี (Generalization) weights ที่เฉพาะเจาะจงกับ training set (ทำให้ค่าที่ทดสอบออกมาดี) เราเรียกว่า overfitting (ทำการจำข้อมูลในคลังข้อมูลแล้วมาตอบคำถามเวลาสอบ) ดังนั้นเราต้องทำยังไงที่จะทำให้เราหา weights ที่ generalization (สร้างองค์ความรู้ออกมาเพื่อใช้ผลิตคำตอบ ต่างจากการจำ) ได้กับข้อมูลที่ไม่ได้อยู่ใน training set ซึ่งบ่อยครั้งที่เมื่อเราลด generalization error จะมีราคาที่ต้องแรกคือ training error จะเพิ่มขึ้น แต่ก็เป็นสิ่งที่รับได้เพราะสุดท้าย training error ที่น้อยมากๆ ก็ไม่สามารถนำไปใช้ประโยชน์จริงได้ แต่กลับ generalization error ที่น้อยเราสามารถนำมันไปใช้ประโยชน์ได้และมั่นใจได้ว่า program เราจะสามารถทำงานกับข้อมูลที่มันไม่เคยเห็นได้ แล้วเราจทำยังไงดี  # ถึงเวลาการทำ regularization การทำ regularization มีหลายแบบตั้งแต่การปรับสมการคำนวณค่า error หรือการเปลี่ยนแปลงโครงสร้างของตัว program (ตัวแปร interact กันยังไง) ขอยกตัวอย่างคร่าวๆโดยการปรับปรุง error โดยเป็นการควบคุม capacity ของ program ในการเรียนรู้ ถ้า capacity สูงเกินไปและปัยหาไม่ซับซ้อนตัว program ก็จะเลือกทางเลือกที่ง่ายที่สุดนั่นคือการจดจำตำตอบ ดังนั้นเราจึงต้องจำกัด capacity ให้เหมาะสมที่จะส่งเสริมให้ program เกิดการเรียนรู้และสร้างองค์ความรู้ขึ้นมาจริงๆ . error = (output - true_output) ** 2 . เราทำการเพิ่มไปอีกสมการหนึ่ง . error = (output - true_output) 2 + sum(weight 2) . จะเห็นว่าเป็นการเอา weights มารวมใน error ด้วย เพื่อเป็นการบอกว่าถ้า weights ไหนไม่ได้มีผลกลับคำตอบจริงๆให้ค่ามุ่งหน้าเข้าสู่ 0 รวมถึง weights ที่มีผลคล้ายๆกันกับคำตอบให้ทำการแชร์ค่ากัน เช่น weight_1 แทนที่จะเป็น 1 ก็ให้เหลือ weight_1 กับ weight_2 เป็น 0.5 แทน การทำแบบนี้ weight แต่ละตัวแปรจะไม่สามารถมีค่าที่มากเกินไปได้ weights แต่ละอันต้องมีการแชร์ และ weights ที่เป็น noise ก็จะต้องถูกปิด (ค่าเข้าใกล้ 0) . แต่สำหรับครั้งนี้ผมจะมาเน้นที่การทำ regularization โดยการปรับตัว program (architecture) โดยการใช้สิ่งที่เรียกว่า dropout . &#3618;&#3636;&#3609;&#3604;&#3637;&#3605;&#3657;&#3629;&#3609;&#3619;&#3633;&#3610; Dropout . การใช้ dropout คือการ random เพื่อทำการ shut down node ที่เลือกลงไป (แทนค่าเป็น 0) ทำไมถึงใช้งานได้ละ? . &#3585;&#3634;&#3619;&#3626;&#3619;&#3657;&#3634;&#3591; neural network program &#3617;&#3634;&#3648;&#3618;&#3629;&#3632;&#3654;&#3627;&#3621;&#3634;&#3618; program &#3649;&#3621;&#3657;&#3623;&#3607;&#3635;&#3585;&#3634;&#3619;&#3648;&#3593;&#3621;&#3637;&#3656;&#3618;&#3588;&#3635;&#3605;&#3629;&#3610; (Ensembling) . เมื่อเราทำการสร้างมาหลายๆ program แน่นอนว่าแต่ละ program ก็จะมีการเรียกรู้ที่ต่างกัน และผิดพลาดต่างกัน เรา overfitting ก็มีการ overfitting ที่ต่างกัน เมื่อ program เรียนรู้จะเรียนรู้สิ่งที่เป็น concept หลักก่อน จากนั้นถ้ายังเหลือ capacity ก็จะเริ่มเรียนรู้รายละเอียดของตัวอย่างนั้นๆ (fine grained detail) เมื่อนำไปใช้ก็จะเกิดข้อผิดพลาดที่แตกต่างกันเพราะมีการ fit noise ที่ต่างกัน ทำให้เมื่อเรานำทั้งหมดมาเฉลี่ยกันจะมีโอกาสที่จะเกิดการ cancel noise ออกไปเหลือแค่ concept หลักที่มีการเรียนรู้ร่วมกัน . แต่การสร้างหลายๆ programs และให้มันเรียนรู้ มันใช้เวลาเยอะมากเลยนะ ดังนั้น dropout จึงเข้ามา นั่นคือเราสร้าง program แค่อันเดียวแล้วทุกครั้งที่มีการใส่ inputs เข้าไปในโปรแกรมเราจะทำการสุ่มปิด nodes ใน program เท่ากับว่าเรามีการสร้าง sub program (sub neural network) ขึ้นมาและที่สำคัญคือ sub program มีจำนวน weights น้อยลงทำให้ลดการเกิด overfitting และถ้าเรามองการทำ dropout คือการสร้าง sub program แสดงว่า sub program หนึ่ง เรียนรู้ batch ของ training set และอีก sub program หนึ่งเรียนรู้อีก batch ของ training set เปรียบเสมือน เราสร้าง 2 program ที่เรียนรู้ข้อมูลคนละส่วน เราเรียกว่า การทำ begging . แต่ dropout ให้เรามากว่านั้นเนื่องจาก sub program ถูกสร้างออกมาจาก program ใหญ่แสดงว่า weights ต้องมีการแชร์กันระหว่าง sub program จำได้ไหม การทำ regularization โดยการปรับสมการ error คือการจำกัดทำให้ค่า weights มุ่งหน้าเข้าสู่ 0 แต่! การทำให้ sub program มีการแชร์ weights กันทำให้ค่า weights ถูกจำกัดและปรับมุ่งหน้าเข้าสู่ค่าที่มันควรจะเป็น (ไม่ใช่ 0)จาก sub program อื่นๆ นี่ยิ่งทำให้ dropout ทรงพลังขึ้นไปอีก แล้วสุดท้ายเราจะมาเฉลี่ยกันยังไง? ถ้า program มี hidden layer แค่ 1 layer การสุ่มเอา sub program มา (จำนวนมากหรือทั้งหมดถ้า node มีไม่มาก) แล้วทำการเฉลี่ยคำตอบก่อนเข้า activation function ใน output nodes จะมีค่าเท่ากับการปิดการทำงานของ dropout หรือการใช้ full program ในการผลิตคำตอบ แล้วนำคำตอบที่ได้มาหารด้วย ratio ของ nodes ที่ปิดไปใน hidden layer . แต่ถ้าเรามี hidden layer มากกว่า 2 การทำแบบเดิมจะไม่ให้ค่าที่ทำกันแล้วแต่ก็ยังสามารถเป็นค่าประมาณที่ใช้จริงได้อยู่ . &#3614;&#3629;&#3649;&#3621;&#3657;&#3623; Theory &#3617;&#3634;&#3621;&#3591;&#3617;&#3639;&#3629;&#3592;&#3619;&#3636;&#3591;&#3585;&#3633;&#3609;&#3648;&#3621;&#3618;&#3604;&#3637;&#3585;&#3623;&#3656;&#3634; . alpha, iterations, hidden_layer1 = 0.01, 500, 32 weight_0_1 = 0.2 * np.random.random(size=(x_train.shape[1], hidden_layer1)) - 0.1 weight_1_2 = 0.2 * np.random.random(size=(hidden_layer1, 10)) - 0.1 . เหมือนเดิม เริ่มแรกมากำหนด learning rate กันก่อนให้เท่ากับ 0.003 (ค่ามากน้อยขึ้นอยู่กับข้อมูลและโครงสร้าง program เรายิ่งค่ามากยิ่งมีการปับ weight มากในครั้งเดียว และยิ่งค่าน้อยก็ยิ่งปรับ weight น้อย มีผลกับเวลาในการเรียนรู้) ต่อมาคือ iteration (epochs) ใช้บอกว่าเราจะให้โปรแกรมเห็น dataset ทุกตัวอย่างทั้งหมดกี่ครั้ง และสุดท้ายจำนวน node ใน hidden layer . weight_0_1 คือ weight ระหว่าง layer 0 (input layer) กับ layer 1 (hidden layer 1) | weight_1_2 คือ weight ระหว่าง layer 1 (hidden layer 1) กับ layer 2 (output layer) | . โดยเราทำการเลื่อนค่าให้มีค่า mean อยู่ที่ - 0.1 และ มีการกะจายของข้อมูลเป็น 0.2 (scale) . for j in range(iterations): error, correct_count = 0, 0 for i in range(x_train.shape[0]): layer_0 = x_train[i:i+1] layer_1 = relu(layer_0.dot(weight_0_1)) dropout_mask = np.random.randint(2, size=layer_1.shape) layer_1 *= dropout_mask * (1/0.5) layer_2 = layer_1.dot(weight_1_2) error += np.sum((layer_2 - y_train[i:i+1]) ** 2) correct_count += int(np.argmax(layer_2) == np.argmax(y_train[i:i+1])) layer_2_delta = layer_2 - y_train[i:i+1] layer_1_delta = derivative_of_relu(layer_1) * (layer_2_delta.dot(weight_1_2.T)) layer_1_delta = layer_1_delta * dropout_mask weight_0_1 -= alpha * layer_0.T.dot(layer_1_delta) weight_1_2 -= alpha * layer_1.T.dot(layer_2_delta) test_error, test_correct_count = 0.0, 0 for i in range(x_test.shape[0]): layer_0 = x_test[i:i+1] layer_1 = relu(layer_0.dot(weight_0_1)) layer_2 = layer_1.dot(weight_1_2) test_error += np.sum((layer_2 - y_test[i:i+1]) ** 2) test_correct_count += int(np.argmax(layer_2) == np.argmax(y_test[i:i+1])) print(f&#39;Error: {error / x_train.shape[0]}&#39;) print(f&#39;Accuracy: {correct_count / x_train.shape[0]}&#39;) print(f&#39;Test Error: {test_error / float(x_test.shape[0])}&#39;) print(f&#39;Test Accuracy: {test_correct_count / x_test.shape[0]}&#39;) . Error: 0.2771398481038192 Accuracy: 0.869 Test Error: 0.3636057630375286 Test Accuracy: 0.8138 . จะเห็นได้ว่า dropout ทำให้ผลการทดสอบกับ testing set ดีขึ้น หมายความว่าทำให้การ generalization ดีขึ้น ส่วนมากการทำให้ program มีการ generalization ดีขึ้นจะต้องมีการแลกเปลี่ยนกับผลลัพธ์ metric ของ training set ในกรณีนี้ยังเราสามารถลองเพิ่มจำนวน iterations ได้เพื่อดูว่าเรายังสามารถปรับปรุง program ให้ดีขึ้นไปได้อีกไหม โดยต้องอย่าลืมตรวจสอบ generalization gap (ความต่างของ error ระหว่าง training และ testing set) มีความกว้างมากไหม ถ้ากว้างมากอาจหมายความว่าเรา overfitting เรียบร้อยแล้ว . Note: ตอนนี้เรากำลังใช้ testing set ในการปรับตัวแปรที่จำเป็นในการสร้าง program เช่นจำนวน iterations หรือ learning rate การทำแบบนี้เป็นการพยายาม overfitting ทางอ้อมกับ testing set ดังนั้นเพื่อป้องกันสถานการณ์นี้เราจะมี validation set มาขั้นกลาง โดยเราใช้ validation set นี้ในการปรับ hyperparameters (parameters ที่ program ไม่ได้ปรับตรงๆในช่วงเรียนรู้ แต่เป็นตัวแปรสำคัญและมีผลต่อการเรียนรู้) . &#3626;&#3640;&#3604;&#3607;&#3657;&#3634;&#3618;&#3649;&#3621;&#3657;&#3623; &#3606;&#3657;&#3634;&#3648;&#3619;&#3634;&#3629;&#3618;&#3634;&#3585;&#3607;&#3635; Batch Gradient Descent &#3621;&#3632;&#3592;&#3632;&#3607;&#3635;&#3618;&#3633;&#3591;&#3652;&#3591; . เราทำการนำตัวแปร gradients ของทุก nodes ใน output layer จากแต่ละ example มาหารด้วยจำนวนสมาชิกใน batch เพราะการปรับ weights ของเราจะขึ้นอยู่กับตัวอย่างทั้งหมดใน batch นั้นเราเลยต้องทำการเฉลี่ยออกมา . Important: ความจริงเรื่องการหารมันเป็นผลเนื่องมาจากสุดท้ายเราคำนวนหา error ของแต่ละตัวอย่างและนำค่า error ทั้งหมดของแต่ละตัวอย่างมารวมกัน ตรงจุดนี้เราทำการหารด้วยตัวอย่างทั้งหมด นั่นทำให้พอเราหา gradients ของแต่ละ nodes จากแต่ละตัวอย่าง จะต้องหารด้วยจำนวนสมาชิกใน batch แต่ถ้าสมการ error เราไม่มีการหารด้วยตัวอย่างทั้งหมด ตอนเราหา gradients ก็ไม่ต้องหารจำนวนสมาชิกทั้งหมดใน batch . batch_size = 100 alpha, iterations, hidden_layer1 = 0.01, 3000, 32 weight_0_1 = 0.2 * np.random.random(size=(x_train.shape[1], hidden_layer1)) - 0.1 weight_1_2 = 0.2 * np.random.random(size=(hidden_layer1, 10)) - 0.1 for j in range(iterations): error, correct_count = 0, 0 for i in range(int(x_train.shape[0] / batch_size)): batch_start, batch_end = (i * batch_size,(i+1) * batch_size) layer_0 = x_train[batch_start:batch_end] layer_1 = relu(layer_0.dot(weight_0_1)) dropout_mask = np.random.randint(2, size=layer_1.shape) layer_1 *= dropout_mask * (1/0.5) layer_2 = layer_1.dot(weight_1_2) error += np.sum((layer_2 - y_train[batch_start:batch_end]) ** 2) for k in range(batch_size): correct_count += int(np.argmax(layer_2[k:k+1]) == np.argmax(y_train[batch_start + k:batch_start + k + 1])) layer_2_delta = (layer_2 - y_train[batch_start:batch_end]) * 1 / batch_size layer_1_delta = derivative_of_relu(layer_1) * (layer_2_delta.dot(weight_1_2.T)) layer_1_delta = layer_1_delta * dropout_mask weight_0_1 -= alpha * layer_0.T.dot(layer_1_delta) weight_1_2 -= alpha * layer_1.T.dot(layer_2_delta) test_error, test_correct_count = 0.0, 0 for i in range(x_test.shape[0]): layer_0 = x_test[i:i+1] layer_1 = relu(layer_0.dot(weight_0_1)) layer_2 = layer_1.dot(weight_1_2) test_error += np.sum((layer_2 - y_test[i:i+1]) ** 2) test_correct_count += int(np.argmax(layer_2) == np.argmax(y_test[i:i+1])) print(f&#39;Error: {error / batch_size}&#39;) print(f&#39;Accuracy: {correct_count / x_train.shape[0]}&#39;) print(f&#39;Test Error: {test_error / float(x_test.shape[0])}&#39;) print(f&#39;Test Accuracy: {test_correct_count / x_test.shape[0]}&#39;) . Error: 3.449173614715377 Accuracy: 0.835 Test Error: 0.3309046876836692 Test Accuracy: 0.8426 . สังเกตว่าการใช้ batch gradient descent จะเป็นการใช้ประโยชน์จากการ optimization ของ linear algebra ทำให้การอัพเดท weights 1 ครั้งเป็นการใช้ตัวอย่างเป็นกลุ่ม ส่งผลให้การประมวลผล training set ใน 1 iteration มีความเร็วมากขึ้น ส่งผลให้เราสามารถเพิ่มจำนวน iterations ได้มากขึ้น นอกจากนี้ถ้ามีการดู error ในทุกๆ iterations ตัว error จะมีแนวโน้มที่มีความเรียบเนียน (smooth) กว่าการอัพเดท weights ที่ละตัวอย่าง . ก่อนจากกัน ทุกคนสามารถลองเล่นโดยการปรับ การ random weights ให้เหมาะสมยิ่งขึ้น (ป้องกัน vanishing gradient), หรือการทำ gradient clip (เพื่อป้องกัน exploding gradient) และ activation functions ดูได้ เพื่อดุประสิทธิภาพของตัว program เมื่อมีการปรับเปลี่ยน activation functions เนื่องจากตัวอย่างที่ได้ทำมาทั้งหมดจะเป็นการใช้ relu ส่วน output nodes ไม่ได้ใช้ activation functions ซึ่งจากโจทย์ข้อนี้ควรจะใช้ softmax หรือ sigmoid ใน output layers เพื่อให้คำตอบอยู่ในช่วง [0, 1] . Note: ถ้าใช้ sigmoid หรือ tanh เป็น hidden layer activation function อย่าลืม random weights ให้เข้าใกล้ 0 เพื่อที่ค่า derivatives จะได้ไม่เข้าใกล้ 0 เกินไปจน program ยากที่จะเรียนรู้หรือปรับปรุง weights หวังว่าทุกคนที่เข้ามาอ่านจะสนุกและได้ความรู้กันนะครับ . Acknowledge . Thank you for all the knowledges from . Deep Learning: Ian Goodfellow and Yoshua Bengio and Aaron Courville | Hands-On Machine Learning with Scikit-Learn and TensorFlow: Concepts, Tools, and Techniques to Build Intelligent Systems: Aurelien Geron | Deep Learning with Python: François Chollet | Neural Networks and Deep Learning: Michael Nielsen | Grokking Deep Learning: Andrew W. Trask | Deep Learning Specialization: Andrew Ng | Python Data Science Handbook: Essential Tools for Working with Data: Jake VanderPlas | . &quot;If you cannot sleep in the night, you need more time to understand it&quot; . Burin Sirisrimungkorn .",
            "url": "https://burins.github.io/whyboyburin/deep%20learning/2020/09/22/Deep-Learning-with-More-Sensation.html",
            "relUrl": "/deep%20learning/2020/09/22/Deep-Learning-with-More-Sensation.html",
            "date": " • Sep 22, 2020"
        }
        
    
  
    
        ,"post1": {
            "title": "(TH) Deep Learning Sensation",
            "content": "Neural Network &#3607;&#3635;&#3629;&#3632;&#3652;&#3619;&#3585;&#3633;&#3609;&#3649;&#3609;&#3656;? . neural network ถ้าเราทำการรื้อดูส่วนประกอบข้างในหน่วยย่อยที่สุดก็คือ ตัวแปรต่างๆ เช่นตัวแปรที่เป็น inputs และตัวแปรที่เป็น weights โดย operation ขั้นพื้นฐานสุดของ neural network ก็คือการคูณ ดังนั้นเราอาจมองได้ว่ามันคือ Power of multiplication . x_input = 2 weight = 3 x_input * weight . 6 . &#3617;&#3634;&#3604;&#3641;&#3585;&#3633;&#3609;&#3648;&#3606;&#3629;&#3632;&#3623;&#3656;&#3634; neural network &#3651;&#3594;&#3657;&#3585;&#3634;&#3619;&#3588;&#3641;&#3603;&#3585;&#3633;&#3609;&#3607;&#3635;&#3585;&#3634;&#3619;&#3626;&#3619;&#3657;&#3634;&#3591;&#3588;&#3635;&#3605;&#3629;&#3610;&#3652;&#3604;&#3657;&#3618;&#3633;&#3591;&#3652;&#3591; . จินตนาการว่าเราอยู่ในดินแดนแห่งปีศาจ โดยในดินแดนนี้มีปีศาจมากมายที่จู่โจมมนุษย์ทำให้เกิดกลุ่มของนักล่าปีศาจขึ้น โดยเราต้องการจะรู้ว่าการล่าปีศาจแต่ละตัวนั้นนักล่าเรามีโอกาสจะชนะหรือเปล่าในการล่าแต่ละครั้งโดยข้อมูลที่เราใช้จะเป็นค่าเฉลี่ยจำนวนปีศาจที่ล่าได้ต่อวัน (ทำการนับจำนวนปีศาจที่ล่าได้ในแต่ละวันแล้วหาค่าเฉลี่ย) มาดูกันว่าเราจะหาคำตอบออกมาได้ยังไงโดยใช้ neural network . weight = 0.1 . เริ่มจากการกำหนดค่า weight ก่อน โดยเราให้ weight มีค่าเป็น 0.1 . number_of_demon = [7.9, 9, 4] . นี่คือค่าเฉลี่ยจำนวนปีศาจที่ล่าได้ต่อวัน เช่นนักล่าคนแรก มีค่าเฉลี่ย 7.9 ตัว ส่วนนักล่าคนที่สอง มีค่าเฉลี่ย 9 ตัว . def neural_network(x_input, weight): prediction = x_input * weight return prediction . เราทำการสร้าง neural network ขึ้นมา สังเกตว่ามันก็คือการคูณกันระหว่างตัวแปรที่เป็น input ซึ่งก็คือค่าเฉลี่ยนิ้วเท้าของนักฟุตบอลในทีมของเรา กับ ตัวแปรที่เป็น weight ซึ่งเรากำหนดค่าไว้คือ 0.1 . x_input = number_of_demon[0] pred = neural_network(x_input, weight) pred . 0.79 . เราทำการเอาค่าจากนักล่าคนแรกมาเป็น input เพราะต้องการรู้ว่านักล่าคนแรกจะชนะปีศาจไหม สุดท้ายเมื่อเราเอามาใส่เข้าไปใน neural network ของเรา ผลลัพธ์คำตอบที่ได้ไม่ได้บอกว่า ชนะหรือไม่ชนะ (1 หรือ 0) แต่บอกเป็นความน่าจะเป็นที่จะชนะ ในกรณีนี้คือมีโอกาสชนะ 79% ว้าว นี่เราสามารถสร้าง neural network ที่สามารถทำการทำนายได้ว่านักล่าที่เราสนใจมีโอกาสชนะปีศาจไหมจากการใช้ข้อมูลค่าเฉลี่ยของจพนวนปีศาจที่ล่าได้ในแต่ละวัน! . Note: ในกรณีนี้เราต้องการคำตอบออกมาเป็นความน่าจะเป็น แต่คำตอบที่เป็นไปได้ไม่ได้มีการจำกัดขอบเขต เดี๋ยวเราจะมาพูดถึงจุดนี้อีกครั้งตอน activation function . &#3585;&#3634;&#3619;&#3621;&#3656;&#3634;&#3611;&#3637;&#3624;&#3634;&#3592;&#3605;&#3633;&#3623;&#3627;&#3609;&#3638;&#3656;&#3591;&#3586;&#3629;&#3591;&#3609;&#3633;&#3585;&#3621;&#3656;&#3634;&#3588;&#3609;&#3627;&#3609;&#3638;&#3656;&#3591;&#3617;&#3637;&#3586;&#3657;&#3629;&#3617;&#3641;&#3621;&#3627;&#3621;&#3634;&#3618;&#3649;&#3591;&#3656;&#3617;&#3640;&#3617;&#3585;&#3623;&#3656;&#3634;&#3649;&#3588;&#3656;&#3592;&#3635;&#3609;&#3623;&#3609;&#3607;&#3637;&#3656;&#3621;&#3656;&#3634;&#3652;&#3604;&#3657;&#3605;&#3656;&#3629;&#3623;&#3633;&#3609; . แต่ความจริงแค่ค่าเฉลี่ยจำนวนปีศาจที่ล่าได้อาจจะยังไม่สามารถการันตีได้ว่าผลลัพธ์ที่ได้ถูกต้องจริงหรือเปล่า ดังนั้นจะต้องมีการเพิ่มมุมมองของข้อมูลเข้าไปเพื่อให้ neural network มีการตัดสินใจในคำตอบที่ดีขึ้น โดยคราวนี้เราไม่ได้ใส่แค่ input ตัวเดียว (ค่าเฉลี่ยจำนวนปีศาจ) แต่มี inputs อีกหลายตัว เข้ามาพิจารณาร่วมด้วย เรานำ inputs ทั้งหมดมาจัดกลุ่มรวมกันและมองทั้งหมดเป็น representation ของข้อมูลที่เราสนใจ ในกรณีนี้คือข้อมูลของแต่ละทีม ซึ่งต่อไปจะขอเรียกข้อมูลย่อยๆ (input แต่ละอัน) ที่ประกอบกันเป็น representation ว่า features . weights = np.array([0.1, 0.3, 0.01]) . คราวนี้จะมีตัวแปร weight ทั้งหมด 3 ตัวแปรเนื่องจากข้อมูลเรามี 3 inputs (feature) . def neural_network(x_input, weights): pred = x_input.dot(weights) return pred . neural network เราเหมือนเดิมเลยคือการนำ input มาคูณกับ weight เพื่อสร้างคำตอบ แต่ แต่... คราวนี้เรามี 3 inputs และ 3 weights ดังนั้นเราก็ทำการคูณกันเป็นคู่ๆ input ไหนคู่กับ weight ไหน ก็นำมาคูณกันสุดท้ายเราจะได้ list ที่มีจำนวนสมาชิกเท่ากับ 3 เพราะเกิดจากการคูณกันของแต่ละคู่ แต่ประเด็นคือเราต้องให้คำตอบออกมาเป็นค่าเดียวนั่นคือความนน่าจะเป็นที่ทีมฟุตบอลของเราจะชนะ แล้วเราจะทำยังไงดี ง่ายมากเราก็แค่เอาผลลัพธ์ที่ได้จากการคูณกันของแต่ละคู่มาบวกรวมกันเป็นค่าเดียว นี่คือคำตอบของเรา! . Note: การคูณกันตามตำแหน่งที่ตรงกันและนำผลลัพธ์จากการคูณกันของแต่ละตำแหน่งมารวมกันเราเรียกว่า weight sum หรือมองเป็นการนำ 2 vectors มาทำ dot product กันนั่นเอง . demons = np.array([7.9, 9, 4]) sword = np.array([0.6, 0.85, 0.9]) gun = np.array([1, 1.9, 0.45]) . เรามีทั้งหมด 3 inputs ได้แก่ ค่าเฉลี่ยจำนวนปีศาจที่ล่าได้ในแต่ละวัน (deamons), ค่าเฉลี่ยจำนวนปีศาจที่ล่าได้ในแต่ละวันโดยใช้ดาบ (sword) ค่าเฉลี่ยจำนวนปีศาจที่ล่าได้ในแต่ละวันโดยใช้ปืน (gun) . x_input = np.array([demons[0], sword[0], gun[0]]) pred = neural_network(x_input, weights) print(pred) . 0.98 . เราทำการดึงข้อมูลของทีมแรกมา (เราเรียกข้อมูลแต่ละ row ว่า example) ซึ่งประกอบด้วยข้อมูลย่อย 3 ส่วน (ข้อมูลแต่ละ column คือ feature) เรานำ input ทั้ง 3 ตัวนี้ไปใส่ใน neural network program ของเรา สุดท้ายเราก็จะได้คำตอบออกมาซึ่งบอกว่านักล่าคนแรกของเรามีโอกาสชนะ 98% Wow! . &#3649;&#3621;&#3657;&#3623;&#3606;&#3657;&#3634;&#3648;&#3619;&#3634;&#3629;&#3618;&#3634;&#3585;&#3652;&#3604;&#3657;&#3588;&#3635;&#3605;&#3629;&#3610;&#3627;&#3621;&#3634;&#3618;&#3654;&#3588;&#3635;&#3605;&#3629;&#3610;&#3621;&#3632;&#3607;&#3635;&#3618;&#3633;&#3591;&#3652;&#3591; . ตอนนี้ neural network สามารถให้คำตอบกับเราได้ว่าทีมเราจะชนะหรือแพ้ แล้วถ้าเราบอกว่าเราอยากรู้ด้วยว่านักล่าคนนี้เมื่อล่าเสร็จมีโอกาสจะเกิดการบาดเจ็บไหม ยิ่งกว่านั้นอยากรู้ด้วยว่าหลังล่าเสร็จนักล่าคนนี้จะอารมณ์เป็นยังไง . Note: output เราจะมีทั้งหมด 3 ตัวแปร ได้แก่ 1.บาดเจ็บ (1) หรือ ไม่บาดเจ็บ (0) 2. ชนะ (1) หรือ แพ้ (0) 3. ปกติ (1) หรือ หดหู่ (0) โดยทั้งหมดค่าจะบ่งบอกถึงความน่าจะเป็น . weight_0_1 = np.array([[0.1, -0.1, 0.1], [0.3, 0.1, 0.4], [0.01, 0.9, 0.1]]) weight_1_2 = np.array([[0.3, 0.1, 0], [1.12, 0.25, 1.3], [-0.3, 0, 0.1]]) weights = [weight_0_1, weight_1_2] . จาก weight_0_1 ถ้าเราโฟกัสไปที่ column แรก แถวทั้งหมดคือ weights ที่ผูกกับ inputs ซึ่งสุดท้ายก็จะได้ค่าออกมาหนึ่งค่าสำหรับ node ที่เราสนใจ (หรือก็คือ column ที่ 1) ผ่านการทำ weight sum สังเกตว่าเรามีอยู่ 3 columns ดังนั้นเราต้องทำการ weight sum ทั้งหมด 3 ครั้ง แปลว่าเราจะได้ 3 nodes ใหม่ ซึ่งขอให้มองว่ามันคือ 3 inputs ใหม่ของเราที่ผ่าน step ครั้งแรกมาทำให้เราได้ representation ใหม่ที่ดีกว่าและเหมาะสมมากขึ้น จากนั้นเราก็นำเอา 3 inputs ใหม่นี้ทำการคำนวณร่วมกับ weight_1_2 สุดท้าย จะได้ 3 nodes ใหม่ออกมาซึ่งในกรณีนี้ก็คือ output ของเรา ที่ให้คำตอบออกมาทั้งหมด 3 คำตอบตามที่เราต้องการ . def neural_network(input, weights): hid = input.dot(weights[0]) pred = hid.dot(weights[1]) return pred demons = np.array([7.9, 9, 4]) sword = np.array([0.6, 0.85, 0.9]) gun = np.array([1, 1.9, 0.45]) input = np.array([demons[0], sword[0], gun[0]]) pred = neural_network(input, weights) pred . array([0.1454, 0.1405, 0.334 ]) . เมื่อเรานำทีมแรกใส่เข้าไปใน neural network program จะได้คำตอบออกมาเป็น โอกาสในการบาดเจ็บ 14.54%, โอกาสในการชนะ 14.05% และโอกาสที่สภาพอารมณ์จะปกติ 33.4% สังเกตว่าตอนนี้ program เราสามารถรับ inputs ได้หลายตัวแปร และให้คำตอบได้หลายคำตอบ โดยการปรับตัวสมการเพิ่มเติมเล็กน้อย . &#3649;&#3621;&#3657;&#3623;&#3588;&#3619;&#3634;&#3623;&#3609;&#3637;&#3657; Neural Network &#3592;&#3632;&#3648;&#3619;&#3637;&#3618;&#3609;&#3619;&#3641;&#3657;&#3618;&#3633;&#3591;&#3652;&#3591; . ที่ผ่านมาเราสร้าง neural network program และทำการผลิตคำตอบออกมาได้ แต่ทำไมมันดูเหมือนโปรแกรมปกติเลยละ เรากำหนดทุกอย่างขึ้นมาเองโดยแค่เปลี่ยนจากการสร้าง rule ด้วย logic ปกติมาเป็นการสร้างสมการคณิตศาสตร์ ดูแล้วไม่เห็นมีการเรียนรู้ของตัวโปรแกรมเลย ถุกแล้วครับ สิ่งที่เราทำไปถ้าสังเกตดีๆเรามีการกำหนดค่า weight เรียบร้อยแล้วเป็นค่าที่ทำให้คำตอบออกมาถูกต้องด้วย! แต่จริงๆค่านี้มันคือเป้าหมายของเราและเป็นสิ่งที่กำหนดว่า program เกิดการรียนรู้หรือเปล่า หลายๆคนคงเริ่มนึกออกแล้วว่าการเรียนรู้ของโปรแกรมก็คือ การปรับค่าตัวแปร weights นั่นเอง! . Warning: เราจะปรับค่า weights ทำไมและเพื่ออะไรละ? . ลองคิดดูว่าเราใส่ข้อมูลให้ neural network program แล้วได้คำตอบออกมา เราจะรู้ได้ไงว่าคำตอบที่ได้ถูกต้อง? คำตอบคือเอาไปเทียบกับคำตอบจริงๆ (เรียกว่า label ที่ติดอยู่กับ example) สุดท้ายเราจะได้ค่า error ออกมา นี่แหละ! เราปรับค่า weights ต่างๆเพื่อทำให้ error เหลือน้อยที่สุด นั่นแปลว่าคำตอบที่ program เราผลิตออกมาก็จะมีความถูกต้อง . weight = 0.1 x_input = 0.4 goal_pred = 0.8 pred = x_input * weight pred . 0.04000000000000001 . กำหนดให้ weight เริ่มต้นมีค่าเท่ากับ 0.1 และให้ input มีค่า 0.4 ส่วนคำตอบที่ควรจะเป็นมีค่า 0.8 สุดท้าย เราทำการใส่ input เข้าไปใน program เพื่อทำการคำนวณหาคำตอบและได้คำตอบออกมาเป็น 0.4 . error = (pred - goal_pred) ** 2 error . 0.5776 . เรานำเอาคำตอบที่ได้จาก program มาเทียบกับคำตอบจริง โดยการหาผลต่างและนำผลลัพธ์มายกกำลัง 2 เพื่อให้ค่า error ที่ได้เป็นบวก . Important: ในกรณีที่เรามีการหาค่าเฉลี่ยของ error จากกลุ่มของ example การยกกำลังจะช่วยให้เราไม่เผลอ cancel ค่า error ของแต่ละ example กันเองจนทำให้ error ต่ำกว่าที่ควรจะเป็น เพราะเราพิจารณาว่ามันจะเป็นบวกหรือลบยังไงมันก็คือ error และการยกกำลังยังมีอีกความหมายคือสนใจความผิดพลาดที่ใหญ่ และปล่อยผ่านความผิดพลาดเล็กๆ . สุดท้าย error ที่คำนวณออกมามีค่าเท่ากับ 0.5776 โอเค! เรารู้ error แล้ว ต่อไปต้องทำยังไงต่อ . &#3648;&#3614;&#3636;&#3656;&#3617;&#3627;&#3619;&#3639;&#3629;&#3621;&#3604; weight &#3604;&#3637;&#3609;&#3632;? . เราลองมาช่วยกันคิดกันว่าวิธีที่ง่ายที่สุดในการปรับ weights ทั้งหลายคืออะไรนะ อืม.... โอเค! ลองนี่ไหม เรามี input 1 ค่า เราทำการสร้าง input มาอีก 2 ค่า . เอา input ที่เราสนใจมาเพิ่มค่าด้วยจำนวนน้อยมากๆ | เอา input ที่เราสนใจมาลดค่าด้วยจำนวนที่น้อยมากๆ ดังนั้น input เราจะมีร่างเงาของ input นี้อีก 2 ค่า ที่มากกว่าและน้อยกว่า input หลักเรา แล้วไงต่อ | weight = 0.1 x_input = 0.4 goal_prediction = 0.8 step_amount = 0.001 . มากำหนดก่อนว่าเราจะปรับ weight เป็นจำนวนทีละเท่าไร ในกรณีนี้เราจะเพิ่มหรือลดด้วยจำนวน 0.001 . for iteration in range(2000): prediction = x_input * weight error = (prediction - goal_prediction) ** 2 up_prediction = x_input * (weight + step_amount) up_error = (up_prediction - goal_prediction) ** 2 down_prediction = x_input * (weight - step_amount) down_error = (down_prediction - goal_prediction) ** 2 if(down_error &lt; up_error): weight = weight - step_amount if(down_error &gt; up_error): weight = weight + step_amount print(f&quot;Error: {error} Prediction: {prediction}&quot;) . Error: 1.5999999996497053e-07 Prediction: 0.8003999999999563 . เราทำการใส่ input เข้าไปในโปรแกรม 2 ครั้ง . ครั้งที่ 1 ใส่ input ที่เป็นร่างเงาที่มีค่ามากกว่า input ดั้งเดิม ได้คำตอบเอาไปคำนวณ error | ครั้งที่ 2 ใส่ input ที่เป็นร่างเงาที่มีค่าน้อยกว่า input ดั้งเดิม ได้คำตอบเอาไปคำนวณ error | สุดท้ายดูว่า input เงาตัวไหนให้ค่า error ที่ต่ำกว่า ก็เลือกการอัพเดท weight ตามนั้น ปัญหาคือถ้าเรามี neural network program ที่ใหญ่มาก และมีจำนวนข้อมูลจนาดใหญ่ที่ต้องใส่เข้าไปใน program การผลิตคำตอบออกมา 2 ครั้งเป็นอะไรที่ไม่ดีแน่ๆ รวมถึงการปรับ weight ของเราจำนวนที่ปรับได้ค่อนข้างจะตามอำเภอใจ ถ้าค่าที่เหมาะสมของ weight ที่เราสนใจไม่สามารถหาได้ด้วยการคูณด้วย step_amount เราก็จะไม่มีวันที่จะหา weight ที่เหมาะสมสำหรับ program ได้ ดังนั้นสิ่งที่ต้องการคือวิธีการปรับ weight ที่ไม่ต้องใช้ neural network program คำนวณหลายรอบและค่าจำนวนที่ใช้ในการปรับ weight สามารถปรับเปลี่ยนได้ตามความเหมาะสม (ตาม error) เพื่อที่จะสามารถหา weight ที่เหมาะสมได้ . &#3585;&#3634;&#3619;&#3588;&#3635;&#3609;&#3623;&#3603;&#3627;&#3634; direction &#3649;&#3621;&#3632; amount &#3626;&#3635;&#3627;&#3619;&#3633;&#3610;&#3585;&#3634;&#3619;&#3611;&#3619;&#3633;&#3610; weight . ก่อนหน้านี้เรารู้แค่ direction ว่า weight ควรจะเพิ่มหรือลด แต่ว่าจำนวนที่ใช้ในการปรับเปลี่ยนเรากำหนดเอง แล้วถ้าเราอยากได้จำนวนคร่าวๆที่เหมาะสมในการปรับเปลี่ยน weight ละ แน่นอนมีวิธีและวิธีการนั้นเรียบง่ายมากเราหยิบเอาตัวแปรออกมา 2 ตัวเพื่อดูความสัมพันธ์จากนั้นดูต่อว่าถ้าเราปรับตัวแปรตัวหนึ่งแล้วตัวแปรอีกตัวมีการเปลี่ยนแปลงไปยังไง . Note: การหาความสัมพันธ์และทำความเข้าใจระหว่าง 2 ตัวแปรก็คือวิชา Calculus ที่เราเคยเรียนกันั่นเอง! . แน่นอนว่าตัวแปรที่เราปรับได้คือ weight และตัวแปรที่เราสังเกตคือ error ว่าเมื่อเราปรับ weight ขึ้นไปนิดนึง error จะมีแนวโน้มยังไง นี่แหละ! เราได้ทั้ง direction และ amount ว่าแต่ทำไม amount ถึงใช้ได้ละลองคิดว่าถ้า error มีการเพิ่มขึ้นอย่างมาก แสดงว่าค่า weight ของเราอยู่ห่างจากค่า weight ที่เหมาะสมพอสมควร (เนื่องจากการคำนวณ error ของเรามีการยกกำลังด้วย)เพราะฉะนั้นเราสามารถปรับ weight ด้วย amount ขนาดใหญ่ตามที่ได้จากการคำนวณได้เลย . weight, goal_pred, x_input = (0.1, 0.8, 0.4) for iteration in range(100): pred = x_input * weight error = (pred - goal_pred) ** 2 delta = pred - goal_pred # raw direction and amount weight_delta = delta * x_input weight = weight - weight_delta print(f&quot;Error: {error} Prediction: {pred}&quot;) . Error: 5.873890229282722e-16 Prediction: 0.7999999757638901 . เริ่มจาก delta คืออะไร? delta คือค่าผลต่างระหว่างคำตอบจาก program และคำตอบที่แท้จริง เป็นการบอกว่าคำตอบเราเนี่ย เยอะไปหรือน้อยไปจากคำตอบจริง ซึ่งค่าที่เราได้เราจะเอาไปบอก weight ที่เชื่อมกับ node นี้ต่อว่า นี่ๆ เจ้า weight ช่วยปรับค่าให้เป็น weight - (x_input x delta) หน่อย ถ้าทำตามที่บอก error จะลดลงแน่นอน . Important: delta คือค่าที่ได้จากการหา derivative ของ pred จากฟังก์ชัน error สุดท้ายเราจะได้ค่าออกมาเป็น pred - goal_pred (จริงๆต้องมีหาร 2 แต่ละเอาไว้เพื่อให้ง่ายต่อการคำนวณและไม่ส่งผลต่อการหา weight) ต่อมาทำการหาค่า derivative ของ weight แต่ละตัว จากฟังก์ชัน weight * x_input ผลลัพธ์ที่ได้คือ x_input สุดท้ายเราใช้ chain rule นำผลลัพธ์ delta มาคูณกับ x_input ก็จะได้ค่า weight_delta ออกมา ซึ่งค่านี้คือสิ่งที่ error ที่เปลี่ยนไป (ลดหรือเพิ่ม) เมื่อเราทำการปรับ weight เพิ่มขึ้นมานิดนึง และนำ weight_delta มาอัพเดท weight ปัจจุบันเพื่อลด error ลงมา . &#3649;&#3605;&#3656;&#3610;&#3634;&#3591;&#3607;&#3637;&#3607;&#3635;&#3652;&#3617;&#3585;&#3634;&#3619;&#3651;&#3594;&#3657; weight_delta &#3652;&#3617;&#3656;&#3648;&#3623;&#3636;&#3619;&#3660;&#3588;&#3609;&#3632; . weight = 0.1 goal_pred = 0.8 x_input = 2 for iteration in range(20): pred = x_input * weight error = (pred - goal_pred) ** 2 delta = pred - goal_pred weight_delta = x_input * delta weight = weight - weight_delta print(f&quot;Error: {error} Prediction: {pred}&quot;) . Error: 4.8630661836227725e+17 Prediction: 697356881.0 . เมื่อ input เรามีค่าเพิ่มขึ้นมากแสดงว่า x_input x delta มีโอกาสที่จะมีค่าที่สูงมาก แสดงว่าเราก้าวเท้าสำหรับการอัพเดทใหญ่เกินไปทำให้เกิด over shooting โดย weight เราจะมีการปรับไป ปรับมา และสุดท้ายก็เกิดการลู่ออก (divergence) ทำไมถึงเป็นอย่างงี้ละ? เนื่อจากพอ input เรามีค่ามากแสดงว่า การปรับ weight นิดเดียวก็ทำให้มีโอกาสที่จะเกิดการเปลี่ยนแปลงของค่า error ขึ้นมาก และเมื่อเกิดการเปลี่ยนแปลงของ error มาก program ก็จะคิดว่า weight ค่าปัจจุบันอยู่ห่างจากค่าที่ต้องการเยอะอยู่งั้นอัพเดทเยอะๆเลยละกัน ทั้งที่ weight ค่าปัจจุบันไม่ได้ห่างจาก weight เป้าหมายมาก สุดท้ายเมื่ออัพเดทก็จะเกิด error มากขึ้นในทิศทางตรงกันข้าม พอลองปรับ weight เพื่อดูการเปลี่ยนแปลงของค่า error ก็ได้ค่า error ที่เปลี่ยนแปลงจำนวนมากขึ้นไปอีก program ก็คิดว่าเราอยู่ไกลขึ้นไปอีกเลยปรับด้วยค่าจำนวนมากขึ้น สุดท้ายก็ได้ค่า error ที่มากขึ้นไปอีกในฝั่งตรงข้าม เป็นแบบนี้ไปเรื่อยๆจนตัว program มีโอกาสจะเกิด error ขึ้นมาจริงๆ (nan) แล้วทำยังไงดี แน่นอนเรามีวิธีจัดการ . &#3586;&#3629;&#3649;&#3609;&#3632;&#3609;&#3635; Alpha &#3627;&#3619;&#3639;&#3629; Learning Rate . ก่อนที่จะอัพเดท weight เราก็ทำการคูณ weight_delta ด้วย alpha เพื่อควบคุม amount ให้ค่าเปลี่ยนแปลงไม่มากจนเกินไปจนเกิด over shooting . weight = 0.1 x_input = 2 goal_pred = 0.8 alpha = 0.1 for iteration in range(20): pred = weight * x_input error = (pred - goal_pred) ** 2 delta = pred - goal_pred weight_delta = x_input * delta weight = weight - (alpha * weight_delta) print(f&quot;Error: {error} Prediction: {pred}&quot;) . Error: 1.336749453880296e-09 Prediction: 0.7999634384155995 . จะเห็นได้ว่า error เราสามารถลดลงได้หลาย level of order of magnitude และคำตอบที่ได้จาก neural network program ก็มีความถูกต้องตามที่ต้องการ สำหรับ Post นี้ โดยสรุปเราได้รู้ว่า neural network ทำงานยังไง ให้คำตอบออกมาได้ยังไง รวมถึงมีการเรียนรู้ขอตัวโปรแกรมได้ยังไง หวังว่าทุกคนจะสนุกและได้รับความรู้กันนะครับ . Acknowledge . Thank you for all the knowledges from . Deep Learning: Ian Goodfellow and Yoshua Bengio and Aaron Courville | Hands-On Machine Learning with Scikit-Learn and TensorFlow: Concepts, Tools, and Techniques to Build Intelligent Systems: Aurelien Geron | Deep Learning with Python: François Chollet | Neural Networks and Deep Learning: Michael Nielsen | Grokking Deep Learning: Andrew W. Trask | Deep Learning Specialization: Andrew Ng | Python Data Science Handbook: Essential Tools for Working with Data: Jake VanderPlas | . &quot;You will understand something when you make it touching the reality.&quot; . Burin Sirisrimungkorn .",
            "url": "https://burins.github.io/whyboyburin/deep%20learning/2020/09/18/Deep-Learning-Sensation.html",
            "relUrl": "/deep%20learning/2020/09/18/Deep-Learning-Sensation.html",
            "date": " • Sep 18, 2020"
        }
        
    
  
    
        ,"post2": {
            "title": "(TH) Brief Understanding of The World of Deep Learning",
            "content": "&#3627;&#3618;&#3640;&#3604;! &#3585;&#3656;&#3629;&#3609;&#3592;&#3632; Deep Learning &#3617;&#3634;&#3607;&#3635;&#3588;&#3623;&#3634;&#3617;&#3619;&#3641;&#3657;&#3592;&#3633;&#3585;&#3585;&#3633;&#3610; Machine Learning &#3585;&#3633;&#3609;&#3585;&#3656;&#3629;&#3609; . เมื่อ computer ถือกำเนิดขึ้นมาบนโลกของเรา มนุษย์ก็เริ่มมีความคิดและความหวังและความฝันว่า computer จะต้องมีความ intelligence ให้ได้ โดยอย่างน้อยก็มีความสามารถเทียบเท่ากับมนุษย์ หรือไปให้เหนือกว่า . Warning: ว่าแต่ที่บอกว่าเหมือนมนุษย์นี่หมายความว่ายังไงกันนะ?   . คอมพิวเตอร์สามารถแก้ไขปัญหาที่สามารถอธิบายได้ในรูปแบบของ formal rule หรือ mathematical rule ซึ่งมีขั้นตอนแบบแผนสวยงาม เราสามารถอธิบายเป็น steps ได้ ซึ่งงานที่สามารถอธิบายเป็น formal หรือ mathematical rule มนุษย์มีความท้าทายในการทำงานพวกนี้สุดๆ ลองบวกเลข 942324 + 134185 ภายใน 5 วินาที โดยห้ามใช้ computer หรือเครื่องคิดเลขนะ! แต่ประเด็นคือมนุษย์ดันเก่งเหลือเกินกับงานที่เราก็ไม่รู้จะอธิบายให้มันเป็น formal knowledge ได้ยังไงเพื่อให้ computer สามารถทำตามและแก้ไขปัญหาได้ เช่น การมองและบอกได้ว่าเราเห็นช้างนะ ถ้าให้เราอธิบายว่าทำไมเราถึงเห็นสิ่งที่มองอยู่เป็นช้างได้ ลองถามคนที่มองสิ่งเดียวกันซัก 100 คน ก็จะเกิด Rule ที่ใช้อธิบายแตกต่างกันไปตามแต่ละคน ที่แปลกคือสมองคนเราสามารถเข้าใจสิ่งนี้ได้ง่ายมาก เรามองดูแล้วรู้ว่ามันคืออะไรเพียงไม่กี่ครั้ง สงสัยเป็นไปได้ว่าสมองของคนเรามีการพัฒนามาตั้งแต่อดีตอย่างต่อเนื่อง (มี pretrained weights เรียบร้อยแล้วสินะ) . ดังนั้นถ้าเราจะสร้าง intelligence computer เราก็ต้องย่อยข้อมูลทั้งหมดบนโลกเราและยัดมันเข้าไปในระบบที่เราสร้าง ซึ่งเคยมีคนทำแล้วโดยการ hardcode knowledge (formal knowledge) เข้าไปในระบบ ระบบสามารถทำงานได้ แต่ แต่... ด้วย rule ทั้งหมดก็ยังไม่ซับซ้อนพอที่จะอธิบายโลกเราได้อย่างสมบูรณ์ สุดท้ายก็เลยไม่ไหวแล้ว เราต้ิองหาวิธีใหม่ที่จะสร้าง informal knowledge เหล่านี้ให้กับ computer เพื่อที่จะบรรลุ (artificial) intelligence computer แล้วเราต้องทำยังไงกันดี? . Machine Learning &#3591;&#3633;&#3657;&#3609;&#3648;&#3627;&#3619;&#3629; . ในเมื่อมันยากนักที่จะย่อยความรู้บนโลกให้เป็น formal knowledge งั้นเราก็ให้ Computer เรียนรู้และสร้างความรู้เองเลยเป็นไงละ การที่ Computer เรียนรู้จากข้อมูลและสร้างองค์ความรู้ขึ้นมาเองในบริบทนั้นๆ เราเรียกว่า Machine (Automatic) Learning (ตรงตัวมากจริงนั่นคือ เครื่องจักรที่เกิดการเรียนรู้) . &#3649;&#3609;&#3623;&#3588;&#3636;&#3604;&#3604;&#3641;&#3648;&#3592;&#3659;&#3591;&#3604;&#3637;&#3649;&#3605;&#3656;&#3617;&#3633;&#3609;&#3607;&#3635;&#3591;&#3634;&#3609;&#3592;&#3619;&#3636;&#3591;&#3654;&#3618;&#3633;&#3591;&#3652;&#3591;? . ให้จินตนาการว่าเราต้องการสร้างหุ่นยนต์ที่สามารถบอกเราว่า วันนี้เหมาะไปเที่ยวไหม ได้แก่ เที่ยว, ไม่เที่ยว โดยหุ่นยนต์ตัวนี้จะบอกคำตอบ(ที่น่าจะเป็น)กับเราได้ก็ต่อเมื่อมันสามารถรับสัญญาณได้ว่าวันนี้ อากาศเป็นยังไงและ วันนี้คือวันอะไรของสัปดาห์ . Note: Input: [สภาพอากาศ, วันของสัปดาห์], Output: [เที่ยว, ไม่เที่ยว] . จินตนาการว่าสมองของหุ่นยนต์เราคือสมการคณิตศาสตร์ (อย่าพึ่งตกใจนะ เรายังไม่ได้เข้าไปสู่โลกของคณิตศาสตร์ แต่ที่ยกมาเพราะอยากสะท้อนสิ่งที่เกิดจริงๆในสมองข้างในของหุ่นยนต์) ดังนั้นตัวแปรอิสระเราก็คือ input และตัวแปรตามคือ output เรานำ input ไปทำ operation (+,-,x,/) กับตัวแปรอีกชุดซึ่งต่อไปจะขอเรียกว่า weights ถ้าเราสุ่มค่าของ weights แต่ละตัว แล้วนำมาทำ operation กับ input สุดท้ายจะได้คำตอบออกมา แต่คำตอบพวกนี้คงอาจจะมีถูกบ้าง ไม่ถูกบ้าง (แน่นอนเพราะเกิดจากการสุ่ม) ดังนั้นการเรียนรู้ของหุ่นยนต์เลยเกิดขึ้น ณ จุดๆนี้ สมองของหุ่นยนต์พยายามปรับ weights (ตัวแปรที่มีความสัมพันธ์กับ input เพื่อผลิต output) ให้ผลลัพธ์จากสมการมีความถูกต้องมากขึ้นเรื่อยๆ จนสุดท้ายเราจะได้ weights ที่เมื่อเจอกับ input จะสามารถให้คำตอบที่ถูกต้องได้ แน่นอนว่า input ของเราสามารถเป็นสิ่งที่ไม่ได้อยู่ในช่วงเรียนรู้ของหุ่นยนต์ได้ นั่นคือเราเอาหุ่นยนต์ไปใช้กับบ้านอื่นๆได้โดยมั่นใจได้ว่าหุ่นยนต์สามารถแก้ปัญหานี้ให้กับคนอื่นได้ เย้! . Important: เมื่อสมการผลิต output จะมีการนำ output ไปเทียบกับ output จริง เพื่อดูความถูกต้อง ดังนั้นเมื่อเกิด error จะมีการแจ้งเตือนไปยัง weights เพื่อบอกว่าสถานะพวกคุณตอนนี้ทำให้ผลลัพธ์ที่ได้จากสมการมีความผิดพลาด กรุณาทำการปรับค่าของพวกคุณให้เหมาะสมด้วย ขอบคุณครับ สุดท้าย weights ก็จะมีการปรับปรุงค่าจนถึงเวลาอันสมควรหรือ ผลลัพธ์ที่ได้มีความถูกต้องจนรับได้ ก็จะหยุดเรียนรู้ และเราสามารถนำ weights นั้นไปใช้งานจริงได้ . Note: Weight: Knowledge (Based On Context), Output: Information (Independent Variable) . &#3614;&#3629;&#3649;&#3621;&#3657;&#3623; Machine Learning &#3649;&#3621;&#3657;&#3623; Deep Learning &#3617;&#3633;&#3609;&#3588;&#3639;&#3629;&#3629;&#3632;&#3652;&#3619;? . ก่อนจะพูดถึง deep learning มาพูดถึงสิ่งหนึ่งก่อน . Neural Network . Neural network เกิดขึ้นมาจากการพยายามสร้างต้นแบบเพื่อจำลองการทำงานของสมองมนุษย์ แต่ต้นแบบที่สร้างมาเอาจริงๆก็ไม่ใช่สิ่งที่สมองเป็นหรือทำงานจริงๆตามรูปแบบนี้ที่จำลองขึ้นมา โดย model ที่สร้างขึ้นมาเรียกว่า perceptron โดยการทำงานคร่าวๆคือ neuron (ต่อไปขอเรียกว่า node) รับกระแสไฟฟ้าจาก nodes ที่เชื่อมต่อกับมัน โดยเส้นที่เชื่อมต่อจะมีค่าพลังงานความเข้มข้นในการเชื่อม (โดยต่อไปจะขอเรียกว่า weight) โดยค่าพลังงานไฟฟ้าที่เข้ามาใน node ปัจจุบันในที่นี้คือค่าพลังงานที่ปล่อยออกจาก node ก่อนหน้า มาคูณกับ weight ที่เชื่อม และเนื่องจาก node หนึ่งสามารถถูกเชื่อมด้วย node ก่อนหน้าได้หลาย nodes ทำให้เกิดการคูณกันของ node กับ weight ที่เชื่อมต่อ เราเลยได้ค่าออกมาเป็น list ที่มีจำนวนสมาชิกเท่ากับจำนวน nodes ก่อนหน้าที่เชื่อมต่อกับ node ปัจจุบัน ดังนั้นเราเลยเอามันมารวมพลังกันเพื่อดูว่าผ่าน threshold หรือไม่(ในอนาคตสิ่งนี้จะกลายเป็น activation function) ถ้าผ่าน node ปัจจุบันจะสามารถปล่อยค่าพลังไปยัง node อื่นต่อไป . แน่นอนว่า model ที่สร้างไม่ได้สะท้อนว่าจริงๆแล้วสมองเราทำงานแบบนี้ ดังนั้นเลยมีการปรับปรุงและพัฒนาต่อไปเรื่อยๆ แต่สุดท้าย deep learning ก็มีช่วงที่คนหมดความเชื่อถืออยู่ 2 ครั้ง . Note: ครั้งที่ 1 เกิดจากการที่ neural network program ไม่สามารถแก้ไขปัญหาที่มีชื่อว่า XOR (neural network มีเพียง 1 layer) ได้ซึ่งเป็นปัญหาที่ simple แต่ในบทความที่เขียนถึงข้อสังเกตนี้ก็ได้บอกต่อว่าปัญหา XOR นี้สามารถแก้ไขได้เมื่อเราเพิ่มจำนวน layer ให้กับ network program แต่สุดท้ายประเด็นแรกก็ถูกยกขึ้นมาและถูกสนใจมากกว่าประเด็นที่ 2 มาก จนคนหมดความหวังกับ neural network ขอต้อนรับสู่ deep learning winter ครั้งที่ 1 . Note: ครั้งที่ 2 เรารู้ถึงไอเดียแล้วว่า neural network สามารถแก้ไขทุกอย่างได้โดยการเพิ่ม layer ทั้งหมดเป็น 2 layers แต่สุดท้ายจะแก้ไขปัญหาให้จบเพียง 2 layers บางปัญหามีความซับซ้อนมากต้องอาศัย patameters (weights) จำนวนมาก นั้นหมายถึงต้องการพลังในการประมวลผลที่สูงและจำนวนข้อมูลที่มาก (prevent overfitting) นั้นทำให้คนเริ่มหมดความหวังกับ deep learning ขอต้อนรับสู่ deep learning winter ครั้งที่ 2 ต่อมามีคนค้นพบว่าปัญหานี้แก้ได้่โดยการเพิ่ม layer มากขึ้นไปอีก โดยมากกว่า 2 layers จำนวน parameters สามารถเพิ่มขึ้นได้โดยที่ไม่ทำให้เกิดการคำนวณมากเกินไป . &#3611;&#3632;&#3623;&#3633;&#3605;&#3636;&#3650;&#3604;&#3618;&#3618;&#3656;&#3629;&#3617;&#3634;&#3585;&#3654;&#3586;&#3629;&#3591; Deep Learning &#3649;&#3621;&#3632;&#3606;&#3639;&#3629;&#3650;&#3629;&#3585;&#3634;&#3626;&#3586;&#3629;&#3610;&#3588;&#3640;&#3603;&#3607;&#3640;&#3585;&#3588;&#3609;&#3607;&#3637;&#3656;&#3617;&#3637;&#3626;&#3656;&#3623;&#3609;&#3619;&#3656;&#3623;&#3617;&#3651;&#3609;&#3611;&#3619;&#3632;&#3623;&#3633;&#3605;&#3636;&#3624;&#3634;&#3626;&#3605;&#3619;&#3660;&#3588;&#3619;&#3633;&#3657;&#3591;&#3609;&#3637;&#3657; . Deep learning ที่กำลังเป็นส่วนสำคัญในการสร้างอนาคตไปด้วยกันกับเรา เกือบที่จะหายไปหลายครั้งแล้วแต่โชคดีที่เรามีคนที่อยู่เบื้องหลังที่ยังคอยพัฒนา, วิจัยและผลักดัน deep learning ให้สามารถดำเนินต่อไปได้ หลังจากที่ผ่านช่วง hype และมีความคาดหวังที่สูง neural network ก็ถูกปัดออกจากการเป็นสิ่งที่น่าสนใจของคนหมู่มากในช่วง 1990s และ 2000s และมีเพียงนักวิจัยไม่มากที่ยังคอยพัฒนาและมีความเชื่อว่าซักวันจะถึงเวลาของพระเอกของเรา deep learning! . โดยผู้อยู่เบื้องหลังทั้ง 3 คนที่ยังคงมีความเชื่อมั่นว่า deep learning คืออนาคตของ AI ได้แก่ Yann Lecun, Yoshua Bengio และ Geoffrey Hinton ทั้ง 3 เป็นผู้ที่ได้รับรางวัล Turing Award ซึ่งเป็นรางวัลสูงสุดของสายงาน Computer Science เปรียบได้กับรางวัลออสการ์จากวงการภาพยนตร์ Lecun ได้ทำงานเกี่ยวกับ convolutional neural network (CNN) โดยได้สร้าง deep learning program ที่สามารถบอกได้ว่าตัวเลขที่เขียนด้วยลายมือเป็นเลขอะไร (MNIST dataset) และถูกนำไปใช้ในการแง่มุมของธุรกิจเพื่อใช้อ่านตัวเลขจากลายมือ โดยคิดเป็น 10% จากงานทั้งหมดที่เกิดขึ้นใน US . จริงๆแล้วไม่ได้มีแค่ 3 คนที่ยังคอยผลักดัน ยังมีนักวิจัยอีกบางส่วนที่ได้สร้างไอเดียที่สำคัญและปัจจุบันก็เป็นเทคนิคที่นิยมมากๆนั้นคือ Long Shot Term Memory (LSTM) โดย Jurgen Schmidhuber และนักเรียนชื่อ Sepp Hocheriter . นอกจากนี้ในปี 1974 Paul Werbos ได้คิดค้นเทคนิคที่มีชื่อว่า back propagation เทคนิคที่ปัจจุบันถูกใช้เป็นเทคนิคหลักในการเรียนรู้ของ neural network program ถึงแม้ว่าเทคนิคนี้จะทรงพลังแค่ไหนก็ยังถูกมองข้ามเป็นหลักสิบปี เพราะคนไม่ให้ความสำคัญกับ neural network แต่ในปัจจุบัน back propagation คือเทคนิคสำคัญสำหรับการสร้าง AI ด้วย deep learning . จะเห็นว่า deep learning ได้ผ่านช่วงที่อยากลำบากมาหลายครั้ง ถ้าเราไม่มีคนที่คอยวิจัยและผลักดันก็จะไม่เกิดสิ่งที่เราให้ความสนใจอยู่ในปัจจุบันและสิ่งที่เป็นกำลังหลักในการสร้างอนาคตและยกระดับความสามารถของมนุษย์ขึ้นไปอีกขั้น . ต้องขอขอบคุณทุกคนที่มีส่วนในการสร้างและผลักดันทั้งในอดีตและปัจจุบันรวมถึงอนาคต โดยปัจจุบันผลลัพธ์ของสิ่งนั้นได้เห็นผลแล้วและคนก็มีความสนใจกันมากขึ้น รวมถึงการทำให้ deep learning เข้าถึงได้ง่ายมากขึ้นด้วย framework ต่างๆ ความคาดหวังของผมต่อไปคือการไปต่อและสร้างความก้าวหน้าในสิ่งที่เรายังไม่รู้ในตอนนี้ . ในปี 1943 เรามี model แรก ที่พยายามใช้ในการทำความเข้าใจการทำงานของสมองมนุษย์ | ช่วงปี 1950 perceptron model สามารถปรับ weights ได้ด้วยตนเอง (ไม่มีมนุษย์มาคอยดูและปรับ) ด้วย optimization algorithm ที่มีชื่อว่า SGD แต่ก็แก้ไขได้แค่ปัญหาที่เป็น linear function | ในปี 1969 perceptron model ไม่สามารถแก้ไขปัญหา non linear functions ได้ ซึ่งประเด็นนี้ทำให้งานวิจัย neural network แทบจะถูกทิ้งและไม่ได้รับความสนใจ | มีกลุ่มของนักวิจัยที่ยังพัฒนาและสร้าง neural network อย่างเงียบๆ | ประมาณช่วง 1970s มีการคิดค้น back propagation algorithm ใช้สำหรับการเรียนรู้ของ neural network ที่มีมากกว่า 2 layers แต่ก็ยังไม่เป็นที่นิยมเพราะต้องการพลังงานในการประมวลผลและข้อมูลจำนวนมาก | ในปี 1988 เรามี CNN เกิดขึ้นบนโลกเรา | ประมาณปี 2000 deep learning เริ่มกับมาเป็นที่สนใจ ต้องขอบคุณพลังของการประมวลผล(ขอบคุณ GPUs) จำนวนข้อมูลที่มากและมีการสร้าง datasets กันแบบจริงจัง รวมถึงการทำเป็น standard เพื่อกระตุ้นให้เกิดการพัฒนาอย่างต่อเนื่อง รวมถึง software ในแง่การสร้างพัฒนา และในแง่การเรียนรู้ของ computer ผ่านการทำงานแบบ distributed | . &#3649;&#3621;&#3657;&#3623;&#3592;&#3619;&#3636;&#3591;&#3654; Deep Learning &#3588;&#3639;&#3629;&#3629;&#3632;&#3652;&#3619;&#3606;&#3657;&#3634;&#3648;&#3619;&#3634;&#3652;&#3617;&#3656;&#3617;&#3629;&#3591;&#3617;&#3633;&#3609;&#3648;&#3611;&#3655;&#3609;&#3585;&#3634;&#3619;&#3592;&#3635;&#3621;&#3629;&#3591;&#3585;&#3634;&#3619;&#3607;&#3635;&#3591;&#3634;&#3609;&#3586;&#3629;&#3591;&#3626;&#3617;&#3629;&#3591;&#3617;&#3609;&#3640;&#3625;&#3618;&#3660; . ผมมอง deep learning ในแง่ของการเป็น program หรือจะพูดแบบเจาะจงคือ multi step program โดยแต่ละ layer คือ represntation state ของข้อมูล (หรือ state ความคิดของ program ณ จุดนั้นๆ) โดยในแต่ละ step เราทำการปรับปรุง state (representation) โดยการนำมาผ่าน simple non linear function เพื่อที่จะได้ state ใหม่ที่ถูกปรับปรุง จะสังเกตได่ว่า program มีการคำนวณเป็น step และทุก step เราจะได้ representation state ที่มีความ high level, abstract และ meaningful ลองจินตนาการว่า ถ้าเราต้องเขียนสมการที่ทำการแปลงรูปภาพให้กลายเป็นผลลัพธ์จากการตรวจจับว่ามีรถหรือคนในรูปภาพไหม ตัวสมการจะมีความยากและซับซ้อนมากๆ แต่ถ้าเราแบ่งมันออกมาเป็น step by step โดยการผ่านรูปภาพไปยัง step แรกเราจะได้ representation ใหม่ออกมาที่บอกว่าในรูปเรามี edge ที่ทำมุมต่างๆที่เราสนใจไหม จากนั้นเอาข้อมูลนี้ไปผ่าน step ที่ 2 จะได้ representation ออกมาว่ามีรูปทรงเรขาคณิตต่างๆเหล่านี้บ้างไหม แล้วเมื่อเราผ่านแต่ละ steps ไปเรื่อยๆ สุดท้ายเราก็จะเจอ step ที่ทำหน้าที่ในการตรวจจับว่าจาก representation state ปัจจุบันนี้ มีคนหรือรถอยู่บ้างไหม แทนที่เราจะคิดสมการที่ซับซ้อนที่สามารถให้คำตอบว่ามีรถหรือคนไหมจาก input ที่เป็นรูปภาพ ซึ่งต่ออาศัย parameters และการคำนวณมหาศาล เราแตกย่อยออกมาเป็นหลายๆ step โดยแต่ละ step ทำการ transform ด้วยสมการที่ไม่ซับซ้อน . &#3617;&#3637;&#3585;&#3634;&#3619;&#3614;&#3641;&#3604;&#3606;&#3638;&#3591; Representation &#3610;&#3656;&#3629;&#3618;&#3617;&#3634;&#3585;&#3649;&#3626;&#3604;&#3591;&#3623;&#3656;&#3634;&#3617;&#3633;&#3609;&#3626;&#3635;&#3588;&#3633;&#3597;&#3651;&#3594;&#3656;&#3652;&#3627;&#3617; . ประเด็นหลักของ deep learning คือเราจะหา representation ที่ดีหรือเหมาะสมยังไง ลองคิดดูว่าถ้าเราต้องค้นหาเลขที่เราสนใจจากข้อมูล array ที่มีขนาดใหญ่มาก จาก 2 array ที่มีข้อมูลข้างในเหมือนกันทุกอย่างแต่ต่างกันตรงที่ . Array ที่มีการเรียงจากน้อยไปหามาก | Array ที่ไม่มีการเรียงลำดับ | คิดว่าแบบไหนจะทำให้เราหาเลขที่เราสนใจได้สะดวกกว่ากัน คำตอบก็คือแบบที่ 2 ดังนั้นสิ่งที่ deep learning ทำคือการหา representation ที่ดี เพื่อที่เราจะสามารถแก้ไขปัญหาได้โดยการใช้เพียง simple linear function (output layer ใช้ weight sum ในกรณีต้องการคำตอบที่เป็น continuous value) deep learning ทำการสร้าง hirarchical representation learning โดยเมื่อผ่าน step 1 มาแล้วอาจจะยังไม่ใช่ Representation ที่ดีที่สุด . Note: representation ที่บอกว่าเจอ edges มุมต่างๆไหม ยังไม่มีความหมายในการเอามาใช้บอกได้ว่ามีคนหรือรถอยู่ในภาพไหม เพราะผลลัพธ์จากการตรวจจับว่าเกิดเส้นด้วยมุมต่างๆ มันสามารถเปลี่ยนแปลงได้ตามปัจจัยที่ส่งผลให้ภาพเปลี่ยนแปลงเช่น การเคลื่อนที่ของ object, แสง เป็นต้น (ยกเว้นภาพนี้จะไม่มีปัจจัยเหล่านี้เข้ามากระทบ เราก็อาจจะตั้งสมมุติฐานได้ว่าถ้าเกิดเส้นองศาตามนี้ ที่ตำแหน่งนี้ ก็แปลว่ามีคน แต่ในโลกความเป็นจริงจะไม่เป็นเช่นนี้) . ดังนั้นจึงทำการไป step ต่อไปเรื่อยๆ จนสุดท้ายได้ representation ที่เหมาะสมที่สามารถให้คำตอบของปัญหาได้ง่ายๆโดยใช้สมการที่ไม่ซับซ้อน . &#3648;&#3619;&#3634;&#3626;&#3634;&#3617;&#3634;&#3619;&#3606;&#3617;&#3629;&#3591; Deep Learning &#3648;&#3611;&#3655;&#3609; program &#3652;&#3604;&#3657; &#3650;&#3604;&#3618;&#3617;&#3629;&#3591;&#3651;&#3609;&#3619;&#3641;&#3611;&#3649;&#3610;&#3610; Computation Graph . ความลึกของ Graph คือ steps ในรูปแบบ Sequence (Layers) | ความกว้างของ Graph คือ steps ในรูปแบบ Parallel (Nodes ในแต่ละ layer) | . Note . การเพิ่มจำนวน feautures ทำให้ model เราแก้ปัญหาได้ดีขึ้นไหม ขึ้นอยู่กับโจทย์ปัญหาของเราให้มองว่าการเพิ่มจำนวน features ก็เหมือนกับการเพิ่ม operation แบบขนาน ส่งผลให้สมการซับซ้อนเพิ่มขึ้น แต่การเพิ่มด้วยแค่ operator คูณและบวก ทำให้ซับซ้อนเพิ่มขึ้นก็จริง แต่ก็อาจจะยังไม่ซับซ้อนพอสำหรับบางปัญหา และก็มีความท้าทายที่จะออกแบบให้ operations แบบขนานมีความซับซ้อนเทียบกับการเพิ่ม operations แบบ sequence (ซึ่งจริงๆ operation sequence ถ้ามองเป็นสมการเดียวก็คือสมการที่ซับซ้อน แต่ในทาง mental เราจะรู้สึกว่ามันง่ายกว่าเพราะเรามองเป็น step และแต่ละ step ก็ใช้ simple transformation) . Acknowledge . Thank you for all the knowledges from . Deep Learning: Ian Goodfellow and Yoshua Bengio and Aaron Courville | Hands-On Machine Learning with Scikit-Learn and TensorFlow: Concepts, Tools, and Techniques to Build Intelligent Systems: Aurelien Geron | Deep Learning with Python: François Chollet | Neural Networks and Deep Learning: Michael Nielsen | Grokking Deep Learning: Andrew W. Trask | Deep Learning Specialization: Andrew Ng | Python Data Science Handbook: Essential Tools for Working with Data: Jake VanderPlas | . &quot;We live in a twilight world.&quot; . Tenet .",
            "url": "https://burins.github.io/whyboyburin/deep%20learning/2020/09/17/Brief-Understanding-of-The-World-of-Deep-Learning.html",
            "relUrl": "/deep%20learning/2020/09/17/Brief-Understanding-of-The-World-of-Deep-Learning.html",
            "date": " • Sep 17, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": ". Burin Sirisrimungkorn . EDUCATION . B.Sc. Computer Science (2014 - 2018) : School of Information Technology, King Mongkut’s University of Technology Thonburi. (KMUTT) | One Semester Exchange (2016) : Department of Computer and Information Science, Faculty of Engineering, Tokyo University of Agriculture and Technology (TUAT) ASEAN International Mobility for Students Programme. (AIMS) | . EXPERIENCE . Diabetics Retinopathy Detection (2018 - 2019) : Building and researching mathematical neural network models for detecting diabetics retinopathy with Mettapracharak hospital. | Smart Shopping with Receipt Recognition (2017) : A home inventory management application with object character recognition by using Cloud Vision on Google Cloud platform. | Big Data School internship at IMC Institute (2017) : Developing stock market model by using Monte Carlo algorithm and learning Google Cloud platform with Hadoop ecosystem. | Research Internship in Field of Mathematical Optimization (2016) : Tokyo University of Agriculture and Technology, Tokyo Japan. In the topic “Optimization of Traveling Tournament problem in Sport Scheduling using Integer Programming Model” with supervised by Prof. Ryuhei Miyashiro. | Author of Python Programming Tutorial Book (2016) : A book used for tutorial at 12th Junior Programmer Camp in university. | . ACTIVITIES . MU Space Machine learning Hackathon (2020): Award Winner. | Deep learning Hackathon hosted by Kasetsart University (2017) : Award Winner Best Application. | Academic leader in 12th Junior Programmer Camp at SIT, KMUTT (2016) : Teaching and preparing basic Python programming. | Raspberry PI Workshop at SIT, KMUTT (2016) : Teaching Raspberry PI for freshman. | . .",
          "url": "https://burins.github.io/whyboyburin/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://burins.github.io/whyboyburin/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}