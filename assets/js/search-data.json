{
  
    
        "post0": {
            "title": "Neural Network ทำอะไรกันแน่?",
            "content": "&gt; Deep Learning มันเป็นยังไงกันนะ - toc: true - badges: false - comments: true - categories: [deep learning] - author: Burin Sirisrimungkorn . x_input = 2 weight = 3 x_input * weight . 6 . &#3617;&#3634;&#3604;&#3641;&#3585;&#3633;&#3609;&#3648;&#3606;&#3629;&#3632;&#3623;&#3656;&#3634; neural network &#3651;&#3594;&#3657;&#3585;&#3634;&#3619;&#3588;&#3641;&#3603;&#3585;&#3633;&#3609;&#3607;&#3635;&#3585;&#3634;&#3619;&#3626;&#3619;&#3657;&#3634;&#3591;&#3588;&#3635;&#3605;&#3629;&#3610;&#3652;&#3604;&#3657;&#3618;&#3633;&#3591;&#3652;&#3591; . จินตนาการว่าเราต้องการรู้ว่าทีมฟุตบอลเราจะชนะไหมในแต่ละการแข่งขัน โดยข้อมูลที่เราใช้จะเป็นค่าเฉลี่ยนิ้วเท้าของสมาชิกในทีมฟุตบอล (ทำการนับนิ้วเท้าทั้งหมดของสมาชิกในทีมแล้วหาค่าเฉลี่ย) มาดูกันว่าเราจะหาคำตอบออกมาได้ยังไงโดยใช้ neuralnetwork . weight = 0.1 . เริ่มจากการกำหนดค่า weight ก่อน โดยเราให้ weight มีค่าเป็น 0.1 . number_of_toes = [8.5, 9.5, 10, 9] . นี่คือค่าเฉลี่ยนิ้วเท้าของนักฟุตบอลในแต่ละทีม เช่นทีมที่ 1 มีค่าเฉลี่ย 8.5 นิ้ว ส่วนทีมที่ มีค่เฉลี่ย 9.5 นิ้ว . def neural_network(x_input, weight): prediction = x_input * weight return prediction . เราทำการสร้าง neural network ขึ้นมา สังเกตว่ามันก็คือการคูณกันระหว่างตัวแปรที่เป็น input ซึ่งก็คือค่าเฉลี่ยนิ้วเท้าของนักฟุตบอลในทีมของเรา กับ ตัวแปรที่เป็น weight ซึ่งเรากำหนดค่าไว้คือ 0.1 . x_input = number_of_toes[0] pred = neural_network(x_input, weight) pred . 0.8500000000000001 . เราทำการเอาค่าจากการทีมแรกมาเป็น input เพราะต้องการรู้ว่าทีมแรกจะชนะไหม สุดท้ายเมื่อเราเอามาใส่เข้าไปใน neural network ของเรา ผลลัพธ์คำตอบที่ได้ไม่ได้บอกว่า ชนะหรือไม่ชนะ (1 หรือ 0) แต่บอกเป็นความน่าจะเป็นที่จะชนะ ในกรณีนี้คือมีโอกาสชนะ 85% ว้าว นี่เราสามารถสร้าง neural network ที่สามารถทำการทำนายได้ว่าทีมที่เราสนใจมีโอกาสชนะไหมจากการใช้ข้อมูลค่าเฉลี่ยของนิ้วเท้านักฟุตบอลในทีม! . &#3585;&#3634;&#3619;&#3649;&#3586;&#3656;&#3591;&#3586;&#3633;&#3609;&#3588;&#3619;&#3633;&#3657;&#3591;&#3627;&#3609;&#3638;&#3656;&#3591;&#3586;&#3629;&#3591;&#3607;&#3637;&#3617;&#3627;&#3609;&#3638;&#3656;&#3591;&#3617;&#3637;&#3586;&#3657;&#3629;&#3617;&#3641;&#3621;&#3627;&#3621;&#3634;&#3618;&#3649;&#3591;&#3656;&#3617;&#3640;&#3617;&#3585;&#3623;&#3656;&#3634;&#3649;&#3588;&#3656;&#3609;&#3636;&#3657;&#3623;&#3648;&#3607;&#3657;&#3634; . แต่ความจริงแค่ค่าเฉลี่ยนิ้วเท้าอาจจะยังไม่สามารถการันตีได้ว่าผลลัพธ์ที่ได้ถูกต้องจริงหรือเปล่า ดังนั้นจะต้องมีการเพิ่มมุมมองของข้อมูลเข้าไปเพื่อให้ neural network มีการตัดสินใจในคำตอบที่ดีขึ้น โดยคราวนี้เราไม่ได้ใส่แค่ input ตัวเดียว (ค่าเฉลี่ยนิ้วเท้า) แต่มี inputs อีกหลายตัว เข้ามาพิจารณาร่วมด้วย เรานำ inputs ทั้งหมดมาจัดกลุ่มรวมกันและมองทั้งหมดเป็น representation ของข้อมูลที่เราสนใจ ในกรณีนี้คือข้อมูลของแต่ละทีม ซึ่งต่อไปจะขอเรียกข้อมูลย่อยๆ (input แต่ละอัน) ที่ประกอบกันเป็น representation ว่า features . weights = np.array([0.1, 0.2, 0]) . คราวนี้จะมีตัวแปร weight ทั้งหมด 3 ตัวแปรเนื่องจากข้อมูลเรามี 3 inputs (feature) . def neural_network(x_input, weights): pred = x_input.dot(weights) return pred . neural network เราเหมือนเดิมเลยคือการนำ input มาคูณกับ weight เพือ่สร้างคำตอบ แต่ แต่... คราวนี้เรามี 3 inputs และ 3 weights ดังนั้นเราก็ทำการคูณกันเป็นคู่ๆ input ไหนคู่กับ weight ไหน ก็นำมาคูณกันสุดท้ายเราจะได้ list ที่มีจำนวนสมาชิกเท่ากับ 3 เพราะเกิดจากการคูณกันของแต่ละคู่ แต่ประเด็นคือเราต้องให้คำตอบออกมาเป็นค่าเดียวนั่นคือความนน่าจะเป็นที่ทีมฟุตบอลของเราจะชนะ แล้วเราจะทำยังไงดี ง่ายมากเราก็แค่เอาผลลัพธ์ที่ได้จากการคูณกันของแต่ละคู่มาบวกรวมกันเป็นค่าเดียว นี่คือคำตอบของเรา! . Note: การคูณกันตามตำแหน่งที่ตรงกันและนำผลลัพธ์จากการคูณกันของแต่ละตำแหน่งมารวมกันเราเรียกว่า weight sum หรือมองเป็นการนำ 2 vectors มาทำ dot product กันนั่นเอง . toes = np.array([8.5, 9.5, 9.9, 9.0]) win_loss = np.array([0.65, 0.8, 0.8, 0.9]) nfans = np.array([1.2, 1.3, 0.5, 1.0]) . เรามีทั้งหมด 3 inputs ได้แก่ ค่าเฉลี่ยนิ้วเท้าของนักฟุตบอลของแต่ละทีม (toes), อัตราการชนพและแพ้ของแต่ละทีม (win_loss) และจำนวนแฟนคลับของแต่ละทีม (nfans) . x_input = np.array([toes[0], wlrec[0], nfans[0]]) pred = neural_network(x_input, weights) print(pred) . 0.9800000000000001 . เราทำการดึงข้อมูลของทีมแรกมา (เราเรียกข้อมูลแต่ละ row ว่า example) ซึ่งประกอบด้วยข้อมูลย่อย 3 ส่วน (ข้อมูลแต่ละ column คือ feature) เรานำ input ทั้ง 3 ตัวนี้ไปใส่ใน neural network program ของเรา สุดท้ายเราก็จะได้คำตอบออกมาซึ่งบอกว่าทีมแรกของเรามีโอกาสชนะ 98% Wow! . &#3649;&#3621;&#3657;&#3623;&#3606;&#3657;&#3634;&#3648;&#3619;&#3634;&#3629;&#3618;&#3634;&#3585;&#3652;&#3604;&#3657;&#3588;&#3635;&#3605;&#3629;&#3610;&#3627;&#3621;&#3634;&#3618;&#3654;&#3588;&#3635;&#3605;&#3629;&#3610;&#3621;&#3632;&#3607;&#3635;&#3618;&#3633;&#3591;&#3652;&#3591; . ตอนนี้ neural network สามารถให้คำตอบกับเราได้ว่าทีมเราจะชนะหรือแพ้ แล้วถ้าเราบอกว่าเราอยากรู้ด้วยว่าทีมนี้เมื่อแข่งเสร็จมีโอกาสจะเกิดการบาดเจ็บไหม ยิ่งกว่านั้นอยากรู้ด้วยว่าหลังแข่งเสร็จทีมนีจะอารมณ์เป็นยังไง . Note: output เราจะมีทั้งหมด 3 ตัวแปร ได้แก่ 1.บาดเจ็บ (1) หรือ ไม่บาดเจ็บ (0) 2. ชนะ (1) หรือ แพ้ (0) 3. ดีใจ (1) หรือ เสียใจ (0) โดยทั้งหมดค่าจะบ่งบอกถึงความน่าจะเป็น . weight_0_1 = np.array([[0.1, 0.2, -0.1], [-0.1, 0.1, 0.9], [0.1, 0.4, 0.1]]).T weight_1_2 = np.array([[0.3, 1.1, -0.3], [0.1, 0.2, 0.0], [0.0, 1.3, 0.1]]).T weights = [weight_0_1, weight_1_2] . จาก weight_0_1 ถ้าเราโฟกัสไปที่ column แรก แถวทั้งหมดคือ weights ที่ผูกกับ inputs ซึ่งสุดท้ายก็จะได้ค่าออกมาหนึ่งค่าสำหรับ node ที่เราสนใจ (หรือก็คือ column ที่ 1) ผ่านการทำ weight sum สังเกตว่าเรามีอยู่ 3 columns ดังนั้นเราต้องทำการ weight sum ทั้งหมด 3 ครั้ง แปลว่าเราจะได้ 3 nodes ใหม่ ซึ่งขอให้มองว่ามันคือ 3 inputs ใหม่ของเราที่ผ่าน step ครั้งแรกมาทำให้เราได้ representation ใหม่ที่ดีกว่าและเหมาะสมมากขึ้น จากนั้นเราก็นำเอา 3 inputs ใหม่นี้ทำการคำนวณร่วมกับ weight_1_2 สุดท้าย จะได้ 3 nodes ใหม่ออกมาซึ่งในกรณีนี้ก็คือ output ของเรา ที่ให้คำตอบออกมาทั้งหมด 3 คำตอบตามที่เราต้องการ . def neural_network(input, weights): hid = input.dot(weights[0]) pred = hid.dot(weights[1]) return pred toes = np.array([8.5, 9.5, 9.9, 9.0]) wlrec = np.array([0.65, 0.8, 0.8, 0.9]) nfans = np.array([1.2, 1.3, 0.5, 1.0]) input = np.array([toes[0], wlrec[0], nfans[0]]) pred = neural_network(input, weights) pred . array([0.2135, 0.145 , 0.5065]) . เมื่อเรานำทีมแรกใส่เข้าไปใน neural network program จะได้คำตอบออกมาเป็น โอกาสในการบาดเจ็บ 21.35%, โอกาสในการชนะ 14.5% และโอกาสที่จะดีใจ 50.65% สังเกตว่าตอนนี้ program เราสามารถรับ inputs ได้หลายตัวแปร และให้คำตอบได้หลายคำตอบ โดยการปรับตัวสมการเพิ่มเติมเล็กน้อย . &#3649;&#3621;&#3657;&#3623;&#3588;&#3619;&#3634;&#3623;&#3609;&#3637;&#3657; Neural Network &#3592;&#3632;&#3648;&#3619;&#3637;&#3618;&#3609;&#3619;&#3641;&#3657;&#3618;&#3633;&#3591;&#3652;&#3591; . ที่ผ่านมาเราสร้าง neural network program และทำการผลิตคำตอบออกมาได้ แต่ทำไมมันดูเหมือนโปรแกรมปกติเลยละ เรากำหนดทุกอย่างขึ้นมาเองโดยแค่เปลี่ยนจากการสร้าง rule ด้วย logic ปกติมาเป็นการสร้างสมการคณิตศาสตร์ ดูแล้วไม่เห็นมีการเรียนรู้ของตัวโปรแกรมเลย ถุกแล้วครับ สิ่งที่เราทำไปถ้าสังเกตดีๆเรามีการกำหนดค่า weight เรียบร้อยแล้วเป็นค่าที่ทำให้คำตอบออกมาถูกต้องด้วย! แต่จริงๆค่านี้มันคือเป้าหมายของเราและเป็นสิ่งที่กำหนดว่า program เกิดการรียนรู้หรือเปล่า หลายๆคนคงเริ่มนึกออกแล้วว่าการเรียนรู้ของโปรแกรมก็คือ การปรับค่าตัวแปร weights นั่นเอง! . Warning: เราจะปรับค่า weights ทำไมและเพื่ออะไรละ? . ลองคิดดูว่าเราใส่ข้อมูลให้ neural network program แล้วได้คำตอบออกมา เราจะรู้ได้ไงว่าคำตอบที่ได้ถูกต้อง? คำตอบคือเอาไปเทียบกับคำตอบจริงๆ (เรียกว่า label ที่ติดอยู่กับ example) สุดท้ายเราจะได้ค่า error ออกมา นี่แหละ! เราปรับค่า weights ต่างๆเพื่อทำให้ error เหลือน้อยที่สุด นั่นแปลว่าคำตอบที่ program เราผลิตออกมาก็จะมีความถูกต้อง . weight = 0.5 x_input = 0.5 goal_pred = 0.8 pred = x_input * weight pred . 0.25 . กำหนดให้ weight เริ่มต้นมีค่าเท่ากับ 0.5 และให้ input มีค่า 0.5 ส่วนคำตอบที่ควรจะเป็นมีค่า 0.8 สุดท้าย เราทำการใส่ input เข้าไปใน program เพื่อทำการคำนวณหาคำตอบและได้คพตอบออกมาเป็น 0.25 . error = (pred - goal_pred) ** 2 error . 0.30250000000000005 . เรานำเอาคำตอบที่ได้จาก program มาเทียบกับคำตอบจริง โดยการหาผลต่างและนำผลลัพธ์มายกกำลัง 2 เพื่อให้ค่า error ที่ได้เป็นบวก . Important: ในกรณีที่เรามีการหาค่าเฉลี่ยของ error จากกลุ่มของ example การยกกำลังจะช่วยให้เราไม่เผลอ cancel ค่า error ของแต่ละ example กันเองจนทำให้ error ต่ำกว่าที่ควรจะเป็น เพราะเราพิจารณาว่ามันจะเป็นบวกหรือลบยังไงมันก็คือ error และการยกกำลังยังมีอีกความหมายคือสนใจความผิดพลาดที่ใหญ่ และปล่อยผ่านความผิดพลาดเล็กๆ . สุดท้าย error ที่คำนวณออกมามีค่าเท่ากับ 0.3025 โอเค! เรารู้ error แล้ว ต่อไปต้องทำยังไงต่อ . &#3648;&#3614;&#3636;&#3656;&#3617;&#3627;&#3619;&#3639;&#3629;&#3621;&#3604; weight &#3604;&#3637;&#3609;&#3632;? . เราลองมาช่วยกันคิดกันว่าวิธีที่ง่ายที่สุดในการปรับ weights ทั้งหลายคืออะไรนะ อืม.... โอเค! ลองนี่ไหม เรามี input 1 ค่า เราทำการสร้่าง input มาอีก 2 ค่า . เอา input ที่เราสนใจมาเพิ่มค่าด้วยจำนวนน้อยมากๆ | เอา input ที่เราสนใจมาลดค่าด้วยจำนวนที่น้อยมากๆ ดังนั้น input เราจะมีร่างเงาของ input นี้อีก 2 ค่า ที่มากกว่าและน้อยกว่า input หลักเรา แล้วไงต่อ | weight = 0.5 x_input = 0.5 goal_prediction = 0.8 step_amount = 0.001 . มากำหนดก่อนว่าเราจะปรับ weight เป็นจำนวนทีละเท่าไร ในกรณีนี้เราจะเพิ่มหรือลดด้วยจำนวน 0.001 . for iteration in range(1000): prediction = x_input * weight error = (prediction - goal_prediction) ** 2 up_prediction = x_input * (weight + step_amount) up_error = (up_prediction - goal_prediction) ** 2 down_prediction = x_input * (weight - step_amount) down_error = (down_prediction - goal_prediction) ** 2 if(down_error &lt; up_error): weight = weight - step_amount if(down_error &gt; up_error): weight = weight + step_amount print(&quot;Error:&quot; + str(error) + &quot; Prediction:&quot; + str(prediction)) . Error:1.0799505792475652e-27 Prediction:0.7999999999999672 . เราทำการใส่ input เข้าไปในโปรแกรม 2 ครั้ง . ครั้งที่ 1 ใส่ input ที่เป็นร่างเงาที่มีค่ามากกว่า input ดั้งเดิม ได้คำตอบเอาไปคำนวณ error | ครั้งที่ 2 ใส่ input ที่เป็นร่างเงาที่มีค่าน้อยกว่า input ดั้งเดิม ได้คำตอบเอาไปคำนวณ error | สุดท้ายดูว่า input เงาตัวไหนให้ค่า error ที่ต่ำกว่า ก็เลือกการอัพเดท weight ตามนั้น ปัญหาคือถ้าเรามี neural network program ที่ใหญ่มาก และมีจำนวนข้อมูลจนาดใหญ่ที่ต้องใส่เข้าไปใน program การผลิตคำตอบออกมา 2 ครั้งเป็นอะไรที่ไม่ดีแน่ๆ รวมถึงการปรับ weight ของเราจำนวนที่ปรับได้ค่อนข้างจะตามอำเภอใจ ถ้าค่าที่เหมาะสมของ weight ที่เราสนใจไม่สามารถหาได้ด้วยการคูณด้วย step_amount เราก็จะไม่มีวันที่จะหา weight ที่เหมาะสมสำหรับ program ได้ ดังนั้นสิ่งที่ต้องการคือวิธีการปรับ weight ที่ไม่ต้องใช้ neural network program คำนวณหลายรอบและค่าจำนวนที่ใช้ในการปรับ weight สามารถปรับเปลี่ยนได้ตามความเหมาะสม (ตาม error) เพื่อที่จะสามารถหา weight ที่เหมาะสมได้ . &#3585;&#3634;&#3619;&#3588;&#3635;&#3609;&#3623;&#3603;&#3627;&#3634; direction &#3649;&#3621;&#3632; amount &#3626;&#3635;&#3627;&#3619;&#3633;&#3610;&#3585;&#3634;&#3619;&#3611;&#3619;&#3633;&#3610; weight . ก่อนหน้านี้เรารู้แค่ direction ว่า weight ควรจะเพิ่มหรือลด แต่ว่าจำนวนที่ใช้ในการปรับเปลี่ยนเรากำหนดเอง แล้วถ้าเราอยากได้จำนวนคร่าวๆที่เหมาะสมในการปรับเปลี่ยน weight ละ แน่นอนมีวิธีและวิธีการนั้นเรียบง่ายมากเราหยิบเอาตัวแปรออกมา 2 ตัวเพื่อดูความสัมพันธ์จากนั้นดูต่อว่าถ้าเราปรับตัวแปรตัวหนึ่งแล้วตัวแปรอีกตัวมีการเปลี่ยนแปลงไปยังไง . Note: การหาความสัมพันธ์และทำความเข้าใจระหว่าง 2 ตัวแปรก็คือวิชา Calculus ที่เราเคยเรียนกันั่นเอง! . แน่นอนว่าตัวแปรที่เราปรับได้คือ weight และตัวแปรที่เราสังเกตคือ error ว่าเมื่อเราปรับ weight ขึ้นไปนิดนึง error จะมีแนวโน้มยังไง นี่แหละ! เราได้ทั้ง direction และ amount ว่าแต่ทำไม amount ถึงใช้ได้ละลองคิดว่าถ้า error มีการเพิ่มขึ้นอย่างมาก แสดงว่าค่า weight ของเราอยู่ห่างจากค่า weight ที่เหมาะสมพอสมควร (เนื่องจากการคำนวณ error ของเรามีการยกกำลังด้วย)เพราะฉะนั้นเราสามารถปรับ weight ด้วย amount ขนาดใหญ่ตามที่ได้จากการคำนวณได้เลย . weight, goal_pred, x_input = (0.0, 0.8, 0.5) for iteration in range(100): pred = x_input * weight error = (pred - goal_pred) ** 2 delta = pred - goal_pred # raw direction and amount weight_delta = delta * x_input weight = weight - weight_delta print(&quot;Error: {error} Prediction: {pred}&quot;.format(error=error, pred=pred)) . Error: 1.1700484786446364e-25 Prediction: 0.799999999999658 . เริ่มจาก delta คืออะไร? delta คือค่าผลต่างระหว่างคำตอบจาก program และคำตอบที่แท้จริง เป็นการบอกว่าคำตอบเราเนี่ย เยอะไปหรือน้อยไปจากคำตอบจริง ซึ่งค่าที่เราได้เราจะเอาไปบอก weight ที่เชื่อมกับ node นี้ต่อว่า นี่ๆ เจ้า weight ช่วยปรับค่าให้เป็น weight - (x_input x delta) หน่อย ถ้าทำตามที่บอก error จะลดลงแน่นอน . Important: delta คือค่าที่ได้จากการหา derivative ของ pred จากฟังก์ชัน error สุดท้ายเราจะได้ค่าออกมาเป็น pred - goal_pred (จริงๆต้องมีหาร 2 แต่ละเอาไว้เพื่อให้ง่ายต่อการคำนวณและไม่ส่งผลต่อการหา weight) ต่อมาทำการหาค่า derivative ของ weight แต่ละตัว จากฟังก์ชัน weight * x_input ผลลัพธ์ที่ได้คือ x_input สุดท้ายเราใช้ chain rule นำผลลัพธ์ delta มาคูณกับ x_input ก็จะได้ค่า weight_delta ออกมา ซึ่งค่านี้คือสิ่งที่ error ที่เปลี่ยนไป (ลดหรือเพิ่ม) เมื่อเราทำการปรับ weight เพิ่มขึ้นมานิดนึง และนำ weight_delta มาอัพเดท weight ปัจจุบันเพื่อลด error ลงมา ## แต่บางทีทำไมการใช้ weight_delta ไม่เวิร์คนะ . weight = 0.5 goal_pred = 0.8 x_input = 2 for iteration in range(20): pred = x_input * weight error = (pred - goal_pred) ** 2 delta = pred - goal_pred weight_delta = x_input * delta weight = weight - weight_delta print(&quot;Error: {error} Prediction: {pred}&quot;.format(error=error, pred=pred)) . Error: 5.403406870691965e+16 Prediction: -232452292.5999999 . เมื่อ input เรามีค่าเพิ่มขึ้นมากแสดงว่า x_input x delta มีโอกาสที่จะมีค่าที่สูงมาก แสดงว่าเราก้าวเท้าสำหรับการอัพเดทใหญ่เกินไปทำให้เกิด over shooting โดย weight เราจะมีการปรับไป ปรับมา และสุดท้ายก็เกิดการลู่ออก (divergence) ทำไมถึงเป็นอย่างงี้ละ? เนื่อจากพอ input เรามีค่ามากแสดงว่า การปรับ weight นิดเดียวก็ทำให้มีโอกาสที่จะเกิดการเปลี่ยนแปลงของค่า error ขึ้นมาก และเมื่อเกิดการเปลี่ยนแปลงของ error มาก program ก็จะคิดว่า weight ค่าปัจจุบันอยู่ห่างจากค่าที่ต้องการเยอะอยู่งั้นอัพเดทเยอะๆเลยละกัน ทั้งที่ weight ค่าปัจจุบันไม่ได้ห่างจาก weight เป้าหมายมาก สุดท้ายเมื่ออัพเดทก็จะเกิด error มากขึ้นในทิศทางตรงกันข้าม พอลองปรับ weight เพื่อดูการเปลี่ยนแปลงของค่า error ก็ได้ค่า error ที่เปลี่ยนแปลงจำนวนมากขึ้นไปอีก program ก็คิดว่าเราอยู่ไกลขึ้นไปอีกเลยปรับด้วยค่าจำนวนมากขึ้น สุดท้ายก็ได้ค่า error ที่มากขึ้นไปอีกในฝั่งตรงข้าม เป็นแบบนี้ไปเรื่อยๆจนตัว program มีโอกาสจะเกิด error ขึ้นมาจริงๆ (nan) แล้วทำยังไงดี แน่นอนเรามีวิธีจัดการ . &#3586;&#3629;&#3649;&#3609;&#3632;&#3609;&#3635; Alpha &#3627;&#3619;&#3639;&#3629; Learning Rate . ก่อนที่จะอัพเดท weight เราก็ทำการคูณ weight_delta ด้วย alpha เพื่อควบคุม amount ให้ค่าเปลี่ยนแปลงไม่มากจนเกินไปจนเกิด over shooting . weight = 0.5 x_input = 2 goal_pred = 0.8 alpha = 0.1 for iteration in range(20): pred = weight * x_input error = (pred - goal_pred) ** 2 delta = pred - goal_pred weight_delta = x_input * delta weight = weight - (alpha * weight_delta) print(&quot;Error: {error} Prediction: {pred}&quot;.format(error=error, pred=pred)) . Error: 1.485277170987127e-10 Prediction: 0.8000121871948003 . จะเห็นได้ว่า error เราสามารถลดลงได้หลาย level of order of magnitude และคำตอบที่ได้จาก neural network program ก็มีความถูกต้องตามที่ต้องการ สำหรับ Post นี้ โดยสรุปเราได้รู้ว่า neural network ทำงานยังไง ให้คำตอบออกมาได้ยังไง รวมถึงมีการเรียนรู้ขอตัวโปรแกรมได้ยังไง หวังว่าทุกคนจะสนุกและได้รับความรู้กันนะครับ . &quot;You will understand something when you make it touching the reality.&quot; . Burin Sirisrimungkorn .",
            "url": "https://burins.github.io/whyboyburin/2020/09/18/Deep-Learning-Sensation.html",
            "relUrl": "/2020/09/18/Deep-Learning-Sensation.html",
            "date": " • Sep 18, 2020"
        }
        
    
  
    
        ,"post1": {
            "title": "(TH) Brief Understanding of The World of Deep Learning",
            "content": "&#3627;&#3618;&#3640;&#3604;! &#3585;&#3656;&#3629;&#3609;&#3592;&#3632; Deep Learning &#3617;&#3634;&#3607;&#3635;&#3588;&#3623;&#3634;&#3617;&#3619;&#3641;&#3657;&#3592;&#3633;&#3585;&#3585;&#3633;&#3610; Machine Learning &#3585;&#3633;&#3609;&#3585;&#3656;&#3629;&#3609; . เมื่อ computer ถือกำเนิดขึ้นมาบนโลกของเรา มนุษย์ก็เริ่มมีความคิดและความหวังและความฝันว่า computer จะต้องมีความ intelligence ให้ได้ โดยอย่างน้อยก็มีความสามารถเทียบเท่ากับมนุษย์ หรือไปให้เหนือกว่า . Warning: ว่าแต่ที่บอกว่าเหมือนมนุษย์นี่หมายความว่ายังไงกันนะ?   . คอมพิวเตอร์สามารถแก้ไขปัญหาที่สามารถอธิบายได้ในรูปแบบของ formal rule หรือ mathematical rule ซึ่งมีขั้นตอนแบบแผนสวยงาม เราสามารถอธิบายเป็น steps ได้ ซึ่งงานที่สามารถอธิบายเป็น formal หรือ mathematical rule มนุษย์มีความท้าทายในการทำงานพวกนี้สุดๆ ลองบวกเลข 942324 + 134185 ภายใน 5 วินาที โดยห้ามใช้ computer หรือเครื่องคิดเลขนะ! แต่ประเด็นคือมนุษย์ดันเก่งเหลือเกินกับงานที่เราก็ไม่รู้จะอธิบายให้มันเป็น formal knowledge ได้ยังไงเพื่อให้ computer สามารถทำตามและแก้ไขปัญหาได้ เช่น การมองและบอกได้ว่าเราเห็นช้างนะ ถ้าให้เราอธิบายว่าทำไมเราถึงเห็นสิ่งที่มองอยู่เป็นช้างได้ ลองถามคนที่มองสิ่งเดียวกันซัก 100 คน ก็จะเกิด Rule ที่ใช้อธิบายแตกต่างกันไปตามแต่ละคน ที่แปลกคือสมองคนเราสามารถเข้าใจสิ่งนี้ได้ง่ายมาก เรามองดูแล้วรู้ว่ามันคืออะไรเพียงไม่กี่ครั้ง สงสัยเป็นไปได้ว่าสมองของคนเรามีการพัฒนามาตั้งแต่อดีตอย่างต่อเนื่อง (มี pretrained weights เรียบร้อยแล้วสินะ) . ดังนั้นถ้าเราจะสร้าง intelligence computer เราก็ต้องย่อยข้อมูลทั้งหมดบนโลกเราและยัดมันเข้าไปในระบบที่เราสร้าง ซึ่งเคยมีคนทำแล้วโดยการ hardcode knowledge (formal knowledge) เข้าไปในระบบ ระบบสามารถทำงานได้ แต่ แต่... ด้วย rule ทั้งหมดก็ยังไม่ซับซ้อนพอที่จะอธิบายโลกเราได้อย่างสมบูรณ์ สุดท้ายก็เลยไม่ไหวแล้ว เราต้ิองหาวิธีใหม่ที่จะสร้าง informal knowledge เหล่านี้ให้กับ computer เพื่อที่จะบรรลุ (artificial) intelligence computer แล้วเราต้องทำยังไงกันดี? . Machine Learning &#3591;&#3633;&#3657;&#3609;&#3648;&#3627;&#3619;&#3629; . ในเมื่อมันยากนักที่จะย่อยความรู้บนโลกให้เป็น formal knowledge งั้นเราก็ให้ Computer เรียนรู้และสร้างความรู้เองเลยเป็นไงละ การที่ Computer เรียนรู้จากข้อมูลและสร้างองค์ความรู้ขึ้นมาเองในบริบทนั้นๆ เราเรียกว่า Machine (Automatic) Learning (ตรงตัวมากจริงนั่นคือ เครื่องจักรที่เกิดการเรียนรู้) . &#3649;&#3609;&#3623;&#3588;&#3636;&#3604;&#3604;&#3641;&#3648;&#3592;&#3659;&#3591;&#3604;&#3637;&#3649;&#3605;&#3656;&#3617;&#3633;&#3609;&#3607;&#3635;&#3591;&#3634;&#3609;&#3592;&#3619;&#3636;&#3591;&#3654;&#3618;&#3633;&#3591;&#3652;&#3591;? . ให้จินตนาการว่าเราต้องการสร้างหุ่นยนต์ที่สามารถบอกเราว่า วันนี้เหมาะไปเที่ยวไหม ได้แก่ เที่ยว, ไม่เที่ยว โดยหุ่นยนต์ตัวนี้จะบอกคำตอบ(ที่น่าจะเป็น)กับเราได้ก็ต่อเมื่อมันสามารถรับสัญญาณได้ว่าวันนี้ อากาศเป็นยังไงและ วันนี้คือวันอะไรของสัปดาห์ . Note: Input: [สภาพอากาศ, วันของสัปดาห์], Output: [เที่ยว, ไม่เที่ยว] . จินตนาการว่าสมองของหุ่นยนต์เราคือสมการคณิตศาสตร์ (อย่าพึ่งตกใจนะ เรายังไม่ได้เข้าไปสู่โลกของคณิตศาสตร์ แต่ที่ยกมาเพราะอยากสะท้อนสิ่งที่เกิดจริงๆในสมองข้างในของหุ่นยนต์) ดังนั้นตัวแปรอิสระเราก็คือ input และตัวแปรตามคือ output เรานำ input ไปทำ operation (+,-,x,/) กับตัวแปรอีกชุดซึ่งต่อไปจะขอเรียกว่า weights ถ้าเราสุ่มค่าของ weights แต่ละตัว แล้วนำมาทำ operation กับ input สุดท้ายจะได้คำตอบออกมา แต่คำตอบพวกนี้คงอาจจะมีถูกบ้าง ไม่ถูกบ้าง (แน่นอนเพราะเกิดจากการสุ่ม) ดังนั้นการเรียนรู้ของหุ่นยนต์เลยเกิดขึ้น ณ จุดๆนี้ สมองของหุ่นยนต์พยายามปรับ weights (ตัวแปรที่มีความสัมพันธ์กับ input เพื่อผลิต output) ให้ผลลัพธ์จากสมการมีความถูกต้องมากขึ้นเรื่อยๆ จนสุดท้ายเราจะได้ weights ที่เมื่อเจอกับ input จะสามารถให้คำตอบที่ถูกต้องได้ แน่นอนว่า input ของเราสามารถเป็นสิ่งที่ไม่ได้อยู่ในช่วงเรียนรู้ของหุ่นยนต์ได้ นั่นคือเราเอาหุ่นยนต์ไปใช้กับบ้านอื่นๆได้โดยมั่นใจได้ว่าหุ่นยนต์สามารถแก้ปัญหานี้ให้กับคนอื่นได้ เย้! . Important: เมื่อสมการผลิต output จะมีการนำ output ไปเทียบกับ output จริง เพื่อดูความถูกต้อง ดังนั้นเมื่อเกิด error จะมีการแจ้งเตือนไปยัง weights เพื่อบอกว่าสถานะพวกคุณตอนนี้ทำให้ผลลัพธ์ที่ได้จากสมการมีความผิดพลาด กรุณาทำการปรับค่าของพวกคุณให้เหมาะสมด้วย ขอบคุณครับ สุดท้าย weights ก็จะมีการปรับปรุงค่าจนถึงเวลาอันสมควรหรือ ผลลัพธ์ที่ได้มีความถูกต้องจนรับได้ ก็จะหยุดเรียนรู้ และเราสามารถนำ weights นั้นไปใช้งานจริงได้ . Note: Weight: Knowledge (Based On Context), Output: Information (Independent Variable) . &#3614;&#3629;&#3649;&#3621;&#3657;&#3623; Machine Learning &#3649;&#3621;&#3657;&#3623; Deep Learning &#3617;&#3633;&#3609;&#3588;&#3639;&#3629;&#3629;&#3632;&#3652;&#3619;? . ก่อนจะพูดถึง deep learning มาพูดถึงสิ่งหนึ่งก่อน . Neural Network . Neural network เกิดขึ้นมาจากการพยายามสร้างต้นแบบเพื่อจำลองการทำงานของสมองมนุษย์ แต่ต้นแบบที่สร้างมาเอาจริงๆก็ไม่ใช่สิ่งที่สมองเป็นหรือทำงานจริงๆตามรูปแบบนี้ที่จำลองขึ้นมา โดย model ที่สร้างขึ้นมาเรียกว่า perceptron โดยการทำงานคร่าวๆคือ neuron (ต่อไปขอเรียกว่า node) รับกระแสไฟฟ้าจาก nodes ที่เชื่อมต่อกับมัน โดยเส้นที่เชื่อมต่อจะมีค่าพลังงานความเข้มข้นในการเชื่อม (โดยต่อไปจะขอเรียกว่า weight) โดยค่าพลังงานไฟฟ้าที่เข้ามาใน node ปัจจุบันในที่นี้คือค่าพลังงานที่ปล่อยออกจาก node ก่อนหน้า มาคูณกับ weight ที่เชื่อม และเนื่องจาก node หนึ่งสามารถถูกเชื่อมด้วย node ก่อนหน้าได้หลาย nodes ทำให้เกิดการคูณกันของ node กับ weight ที่เชื่อมต่อ เราเลยได้ค่าออกมาเป็น list ที่มีจำนวนสมาชิกเท่ากับจำนวน nodes ก่อนหน้าที่เชื่อมต่อกับ node ปัจจุบัน ดังนั้นเราเลยเอามันมารวมพลังกันเพื่อดูว่าผ่าน threshold หรือไม่(ในอนาคตสิ่งนี้จะกลายเป็น activation function) ถ้าผ่าน node ปัจจุบันจะสามารถปล่อยค่าพลังไปยัง node อื่นต่อไป . แน่นอนว่า model ที่สร้างไม่ได้สะท้อนว่าจริงๆแล้วสมองเราทำงานแบบนี้ ดังนั้นเลยมีการปรับปรุงและพัฒนาต่อไปเรื่อยๆ แต่สุดท้าย deep learning ก็มีช่วงที่คนหมดความเชื่อถืออยู่ 2 ครั้ง . Note: ครั้งที่ 1 เกิดจากการที่ neural network program ไม่สามารถแก้ไขปัญหาที่มีชื่อว่า XOR (neural network มีเพียง 1 layer) ได้ซึ่งเป็นปัญหาที่ simple แต่ในบทความที่เขียนถึงข้อสังเกตนี้ก็ได้บอกต่อว่าปัญหา XOR นี้สามารถแก้ไขได้เมื่อเราเพิ่มจำนวน layer ให้กับ network program แต่สุดท้ายประเด็นแรกก็ถูกยกขึ้นมาและถูกสนใจมากกว่าประเด็นที่ 2 มาก จนคนหมดความหวังกับ neural network ขอต้อนรับสู่ deep learning winter ครั้งที่ 1 . Note: ครั้งที่ 2 เรารู้ถึงไอเดียแล้วว่า neural network สามารถแก้ไขทุกอย่างได้โดยการเพิ่ม layer ทั้งหมดเป็น 2 layers แต่สุดท้ายจะแก้ไขปัญหาให้จบเพียง 2 layers บางปัญหามีความซับซ้อนมากต้องอาศัย patameters (weights) จำนวนมาก นั้นหมายถึงต้องการพลังในการประมวลผลที่สูงและจำนวนข้อมูลที่มาก (prevent overfitting) นั้นทำให้คนเริ่มหมดความหวังกับ deep learning ขอต้อนรับสู่ deep learning winter ครั้งที่ 2 ต่อมามีคนค้นพบว่าปัญหานี้แก้ได้่โดยการเพิ่ม layer มากขึ้นไปอีก โดยมากกว่า 2 layers จำนวน parameters สามารถเพิ่มขึ้นได้โดยที่ไม่ทำให้เกิดการคำนวณมากเกินไป . &#3611;&#3632;&#3623;&#3633;&#3605;&#3636;&#3650;&#3604;&#3618;&#3618;&#3656;&#3629;&#3617;&#3634;&#3585;&#3654;&#3586;&#3629;&#3591; Deep Learning &#3649;&#3621;&#3632;&#3606;&#3639;&#3629;&#3650;&#3629;&#3585;&#3634;&#3626;&#3586;&#3629;&#3610;&#3588;&#3640;&#3603;&#3607;&#3640;&#3585;&#3588;&#3609;&#3607;&#3637;&#3656;&#3617;&#3637;&#3626;&#3656;&#3623;&#3609;&#3619;&#3656;&#3623;&#3617;&#3651;&#3609;&#3611;&#3619;&#3632;&#3623;&#3633;&#3605;&#3636;&#3624;&#3634;&#3626;&#3605;&#3619;&#3660;&#3588;&#3619;&#3633;&#3657;&#3591;&#3609;&#3637;&#3657; . Deep learning ที่กำลังเป็นส่วนสำคัญในการสร้างอนาคตไปด้วยกันกับเรา เกือบที่จะหายไปหลายครั้งแล้วแต่โชคดีที่เรามีคนที่อยู่เบื้องหลังที่ยังคอยพัฒนา, วิจัยและผลักดัน deep learning ให้สามารถดำเนินต่อไปได้ หลังจากที่ผ่านช่วง hype และมีความคาดหวังที่สูง neural network ก็ถูกปัดออกจากการเป็นสิ่งที่น่าสนใจของคนหมู่มากในช่วง 1990s และ 2000s และมีเพียงนักวิจัยไม่มากที่ยังคอยพัฒนาและมีความเชื่อว่าซักวันจะถึงเวลาของพระเอกของเรา deep learning! . โดยผู้อยู่เบื้องหลังทั้ง 3 คนที่ยังคงมีความเชื่อมั่นว่า deep learning คืออนาคตของ AI ได้แก่ Yann Lecun, Yoshua Bengio และ Geoffrey Hinton ทั้ง 3 เป็นผู้ที่ได้รับรางวัล Turing Award ซึ่งเป็นรางวัลสูงสุดของสายงาน Computer Science เปรียบได้กับรางวัลออสการ์จากวงการภาพยนตร์ Lecun ได้ทำงานเกี่ยวกับ convolutional neural network (CNN) โดยได้สร้าง deep learning program ที่สามารถบอกได้ว่าตัวเลขที่เขียนด้วยลายมือเป็นเลขอะไร (MNIST dataset) และถูกนำไปใช้ในการแง่มุมของธุรกิจเพื่อใช้อ่านตัวเลขจากลายมือ โดยคิดเป็น 10% จากงานทั้งหมดที่เกิดขึ้นใน US . จริงๆแล้วไม่ได้มีแค่ 3 คนที่ยังคอยผลักดัน ยังมีนักวิจัยอีกบางส่วนที่ได้สร้างไอเดียที่สำคัญและปัจจุบันก็เป็นเทคนิคที่นิยมมากๆนั้นคือ Long Shot Term Memory (LSTM) โดย Jurgen Schmidhuber และนักเรียนชื่อ Sepp Hocheriter . นอกจากนี้ในปี 1974 Paul Werbos ได้คิดค้นเทคนิคที่มีชื่อว่า back propagation เทคนิคที่ปัจจุบันถูกใช้เป็นเทคนิคหลักในการเรียนรู้ของ neural network program ถึงแม้ว่าเทคนิคนี้จะทรงพลังแค่ไหนก็ยังถูกมองข้ามเป็นหลักสิบปี เพราะคนไม่ให้ความสำคัญกับ neural network แต่ในปัจจุบัน back propagation คือเทคนิคสำคัญสำหรับการสร้าง AI ด้วย deep learning . จะเห็นว่า deep learning ได้ผ่านช่วงที่อยากลำบากมาหลายครั้ง ถ้าเราไม่มีคนที่คอยวิจัยและผลักดันก็จะไม่เกิดสิ่งที่เราให้ความสนใจอยู่ในปัจจุบันและสิ่งที่เป็นกำลังหลักในการสร้างอนาคตและยกระดับความสามารถของมนุษย์ขึ้นไปอีกขั้น . ต้องขอขอบคุณทุกคนที่มีส่วนในการสร้างและผลักดันทั้งในอดีตและปัจจุบันรวมถึงอนาคต โดยปัจจุบันผลลัพธ์ของสิ่งนั้นได้เห็นผลแล้วและคนก็มีความสนใจกันมากขึ้น รวมถึงการทำให้ deep learning เข้าถึงได้ง่ายมากขึ้นด้วย framework ต่างๆ ความคาดหวังของผมต่อไปคือการไปต่อและสร้างความก้าวหน้าในสิ่งที่เรายังไม่รู้ในตอนนี้ . ในปี 1943 เรามี model แรก ที่พยายามใช้ในการทำความเข้าใจการทำงานของสมองมนุษย์ | ช่วงปี 1950 perceptron model สามารถปรับ weights ได้ด้วยตนเอง (ไม่มีมนุษย์มาคอยดูและปรับ) ด้วย optimization algorithm ที่มีชื่อว่า SGD แต่ก็แก้ไขได้แค่ปัญหาที่เป็น linear function | ในปี 1969 perceptron model ไม่สามารถแก้ไขปัญหา non linear functions ได้ ซึ่งประเด็นนี้ทำให้งานวิจัย neural network แทบจะถูกทิ้งและไม่ได้รับความสนใจ | มีกลุ่มของนักวิจัยที่ยังพัฒนาและสร้าง neural network อย่างเงียบๆ | ประมาณช่วง 1970s มีการคิดค้น back propagation algorithm ใช้สำหรับการเรียนรู้ของ neural network ที่มีมากกว่า 2 layers แต่ก็ยังไม่เป็นที่นิยมเพราะต้องการพลังงานในการประมวลผลและข้อมูลจำนวนมาก | ในปี 1988 เรามี CNN เกิดขึ้นบนโลกเรา | ประมาณปี 2000 deep learning เริ่มกับมาเป็นที่สนใจ ต้องขอบคุณพลังของการประมวลผล(ขอบคุณ GPUs) จำนวนข้อมูลที่มากและมีการสร้าง datasets กันแบบจริงจัง รวมถึงการทำเป็น standard เพื่อกระตุ้นให้เกิดการพัฒนาอย่างต่อเนื่อง รวมถึง software ในแง่การสร้างพัฒนา และในแง่การเรียนรู้ของ computer ผ่านการทำงานแบบ distributed | . &#3649;&#3621;&#3657;&#3623;&#3592;&#3619;&#3636;&#3591;&#3654; Deep Learning &#3588;&#3639;&#3629;&#3629;&#3632;&#3652;&#3619;&#3606;&#3657;&#3634;&#3648;&#3619;&#3634;&#3652;&#3617;&#3656;&#3617;&#3629;&#3591;&#3617;&#3633;&#3609;&#3648;&#3611;&#3655;&#3609;&#3585;&#3634;&#3619;&#3592;&#3635;&#3621;&#3629;&#3591;&#3585;&#3634;&#3619;&#3607;&#3635;&#3591;&#3634;&#3609;&#3586;&#3629;&#3591;&#3626;&#3617;&#3629;&#3591;&#3617;&#3609;&#3640;&#3625;&#3618;&#3660; . ผมมอง deep learning ในแง่ของการเป็น program หรือจะพูดแบบเจาะจงคือ multi step program โดยแต่ละ layer คือ represntation state ของข้อมูล (หรือ state ความคิดของ program ณ จุดนั้นๆ) โดยในแต่ละ step เราทำการปรับปรุง state (representation) โดยการนำมาผ่าน simple non linear function เพื่อที่จะได้ state ใหม่ที่ถูกปรับปรุง จะสังเกตได่ว่า program มีการคำนวณเป็น step และทุก step เราจะได้ representation state ที่มีความ high level, abstract และ meaningful ลองจินตนาการว่า ถ้าเราต้องเขียนสมการที่ทำการแปลงรูปภาพให้กลายเป็นผลลัพธ์จากการตรวจจับว่ามีรถหรือคนในรูปภาพไหม ตัวสมการจะมีความยากและซับซ้อนมากๆ แต่ถ้าเราแบ่งมันออกมาเป็น step by step โดยการผ่านรูปภาพไปยัง step แรกเราจะได้ representation ใหม่ออกมาที่บอกว่าในรูปเรามี edge ที่ทำมุมต่างๆที่เราสนใจไหม จากนั้นเอาข้อมูลนี้ไปผ่าน step ที่ 2 จะได้ representation ออกมาว่ามีรูปทรงเรขาคณิตต่างๆเหล่านี้บ้างไหม แล้วเมื่อเราผ่านแต่ละ steps ไปเรื่อยๆ สุดท้ายเราก็จะเจอ step ที่ทำหน้าที่ในการตรวจจับว่าจาก representation state ปัจจุบันนี้ มีคนหรือรถอยู่บ้างไหม แทนที่เราจะคิดสมการที่ซับซ้อนที่สามารถให้คำตอบว่ามีรถหรือคนไหมจาก input ที่เป็นรูปภาพ ซึ่งต่ออาศัย parameters และการคำนวณมหาศาล เราแตกย่อยออกมาเป็นหลายๆ step โดยแต่ละ step ทำการ transform ด้วยสมการที่ไม่ซับซ้อน . &#3617;&#3637;&#3585;&#3634;&#3619;&#3614;&#3641;&#3604;&#3606;&#3638;&#3591; Representation &#3610;&#3656;&#3629;&#3618;&#3617;&#3634;&#3585;&#3649;&#3626;&#3604;&#3591;&#3623;&#3656;&#3634;&#3617;&#3633;&#3609;&#3626;&#3635;&#3588;&#3633;&#3597;&#3651;&#3594;&#3656;&#3652;&#3627;&#3617; . ประเด็นหลักของ deep learning คือเราจะหา representation ที่ดีหรือเหมาะสมยังไง ลองคิดดูว่าถ้าเราต้องค้นหาเลขที่เราสนใจจากข้อมูล array ที่มีขนาดใหญ่มาก จาก 2 array ที่มีข้อมูลข้างในเหมือนกันทุกอย่างแต่ต่างกันตรงที่ . Array ที่มีการเรียงจากน้อยไปหามาก | Array ที่ไม่มีการเรียงลำดับ | คิดว่าแบบไหนจะทำให้เราหาเลขที่เราสนใจได้สะดวกกว่ากัน คำตอบก็คือแบบที่ 2 ดังนั้นสิ่งที่ deep learning ทำคือการหา representation ที่ดี เพื่อที่เราจะสามารถแก้ไขปัญหาได้โดยการใช้เพียง simple linear function (output layer ใช้ weight sum ในกรณีต้องการคำตอบที่เป็น continuous value) deep learning ทำการสร้าง hirarchical representation learning โดยเมื่อผ่าน step 1 มาแล้วอาจจะยังไม่ใช่ Representation ที่ดีที่สุด . Note: representation ที่บอกว่าเจอ edges มุมต่างๆไหม ยังไม่มีความหมายในการเอามาใช้บอกได้ว่ามีคนหรือรถอยู่ในภาพไหม เพราะผลลัพธ์จากการตรวจจับว่าเกิดเส้นด้วยมุมต่างๆ มันสามารถเปลี่ยนแปลงได้ตามปัจจัยที่ส่งผลให้ภาพเปลี่ยนแปลงเช่น การเคลื่อนที่ของ object, แสง เป็นต้น (ยกเว้นภาพนี้จะไม่มีปัจจัยเหล่านี้เข้ามากระทบ เราก็อาจจะตั้งสมมุติฐานได้ว่าถ้าเกิดเส้นองศาตามนี้ ที่ตำแหน่งนี้ ก็แปลว่ามีคน แต่ในโลกความเป็นจริงจะไม่เป็นเช่นนี้) . ดังนั้นจึงทำการไป step ต่อไปเรื่อยๆ จนสุดท้ายได้ representation ที่เหมาะสมที่สามารถให้คำตอบของปัญหาได้ง่ายๆโดยใช้สมการที่ไม่ซับซ้อน . &#3648;&#3619;&#3634;&#3626;&#3634;&#3617;&#3634;&#3619;&#3606;&#3617;&#3629;&#3591; Deep Learning &#3648;&#3611;&#3655;&#3609; program &#3652;&#3604;&#3657; &#3650;&#3604;&#3618;&#3617;&#3629;&#3591;&#3651;&#3609;&#3619;&#3641;&#3611;&#3649;&#3610;&#3610; Computation Graph . ความลึกของ Graph คือ steps ในรูปแบบ Sequence (Layers) | ความกว้างของ Graph คือ steps ในรูปแบบ Parallel (Nodes ในแต่ละ layer) | . &quot;We live in a twilight world.&quot; . Tenet .",
            "url": "https://burins.github.io/whyboyburin/deep%20learning/2020/09/17/Brief-Understanding-of-The-World-of-Deep-Learning.html",
            "relUrl": "/deep%20learning/2020/09/17/Brief-Understanding-of-The-World-of-Deep-Learning.html",
            "date": " • Sep 17, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": ". Burin Sirisrimungkorn . EDUCATION . B.Sc. Computer Science (2014 - 2018) : School of Information Technology, King Mongkut’s University of Technology Thonburi. (KMUTT) | One Semester Exchange (2016) : Department of Computer and Information Science, Faculty of Engineering, Tokyo University of Agriculture and Technology (TUAT) ASEAN International Mobility for Students Programme. (AIMS) | . EXPERIENCE . Diabetics Retinopathy Detection (2018 - 2019) : Building and researching mathematical neural network models for detecting diabetics retinopathy with Mettapracharak hospital. | Smart Shopping with Receipt Recognition (2017) : A home inventory management application with object character recognition by using Cloud Vision on Google Cloud platform. | Big Data School internship at IMC Institute (2017) : Developing stock market model by using Monte Carlo algorithm and learning Google Cloud platform with Hadoop ecosystem. | Research Internship in Field of Mathematical Optimization (2016) : Tokyo University of Agriculture and Technology, Tokyo Japan. In the topic “Optimization of Traveling Tournament problem in Sport Scheduling using Integer Programming Model” with supervised by Prof. Ryuhei Miyashiro. | Author of Python Programming Tutorial Book (2016) : A book used for tutorial at 12th Junior Programmer Camp in university. | . ACTIVITIES . MU Space Machine learning Hackathon (2020): Award Winner. | Deep learning Hackathon hosted by Kasetsart University (2017) : Award Winner Best Application. | Academic leader in 12th Junior Programmer Camp at SIT, KMUTT (2016) : Teaching and preparing basic Python programming. | Raspberry PI Workshop at SIT, KMUTT (2016) : Teaching Raspberry PI for freshman. | . .",
          "url": "https://burins.github.io/whyboyburin/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://burins.github.io/whyboyburin/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}