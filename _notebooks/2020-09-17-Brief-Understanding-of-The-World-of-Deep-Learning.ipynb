{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Brief Understanding-of-The-World-of-Deep-Learning\n",
    "> มาทำความรู้จัก Deep Learning และเรื่องราวแบบย่อมากๆๆ กันดีกว่า\n",
    "\n",
    "- toc: true \n",
    "- badges: false\n",
    "- comments: true\n",
    "- categories: [Deep learning]\n",
    "- author: Burin Sirisrimungkorn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# หยุด! ก่อนจะ Deep Learning มารู้จัก Machine Learning ก่อน\n",
    "\n",
    "เมื่อ Computer ถือกำเนิดขึ้นมาบนโลกของเรา มนุษย์ก็เริ่มมีความคิดและความหวังและความฝันว่า Computer จะต้องมีความ Intelligence ให้ได้โดยอย่างน้อยก็มีความสามารถเทียบเท่ากับมนุษย์ หรือจะดีกว่านั้นไปให้เหนือกว่า \n",
    "\n",
    "> Warning: ว่าแต่ที่บอกว่าเหมือนมนุษย์นี่หมายความว่ายังไงกันนะ?  \n",
    "\n",
    "คอมพิวเตอร์สามารถแก้ไขปัญหาที่สามารถอธิบายได้ในรูปแบบของ Formal Rule หรือ Mathematical Rule มีขั้นตอนแบบแผนสวยงาม เราสามารถอธิบายเป็น steps ได้ ซึ่งงานพวก Formal หรือ Mathematical Rule เป็นสิ่งที่ทำให้มนุษย์เกิดความท้าทายในการทำงานพวกนี้สุดๆ ลองบวกเลข 942324 + 134185 ภายใน 5 วินาที ดูโดยห้ามใช้ Computer หรือ เครื่องคิดเลขนะ! แต่ประเด็นคือมนุษย์ดันเก่งเหลือเกินกับงานพวก Informal Rule หรืองานที่เราก็ไม่รู้จะอธิบายให้ัมันเป็น Formal Knowledge ได้ยังไงเพื่อให้ Computer สามารถทำตามและแก้ไขปัญหาได้ เช่น การมองและบอกได้ว่าเราเห็นช้างนะ ถเาให้เราอธิบายว่าทำไมเราถึงเห็นสิ่งที่มองอยู่เป็นช้างได้ ลองถามคนที่มองสิ่งเดียวกันซัก 100 คน ก็จะเกิด Rule ที่ใช้อธิบายแตกต่างกันไปตามแต่ละคน ที่แปลกคือสมองคนเราสามารถเข้าใจสิ่งนี้ได้ง่ายมาก เรามองดูแล้วรู้ว่ามันคืออะไรเพียงไม่กี่ครั้ง สงสัยเป็นไปได้ว่าสมองคนเราพัฒนามาตั้งแต่อดีตอย่างต่อเนื่อง (มี Pretrained weights เรียบร้อยแล้วสินะ)\n",
    "    \n",
    "ดังนั้นถ้าเราจะสร้าง Intelligence Computer เราก็ต้องย่อยข้อมูลทั้งหมดบนโลกเราและยัดมันเข้าไปใน System ของเรา ซึ่งเคยมีคนทำแล้วโดยการ Hardcode Knowledge (Formal Knowledge) เข้าไปในระบบ ระบบสามารถทำงานได้ แต่ แต่... ด้วย Rule ทั้งหมดก็ยังไม่ซับซ้อนพอที่จะอธิบายโลกเราได้อย่างสมบูรณ์ สุดท้ายก็เลยไม่ไหวแล้ว เราต้ิองหาวิธีใหม่ที่จะสร้าง Informal Knowledge เหล่านี้ให้กับ Computer เพื่อที่จะบรรลุ (Artificial)Intelligence Computer แล้วเราต้องทำยังไงกันดี?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning งั้นเหรอ\n",
    "ในเมื่อมันยากนักที่จะย่อยความรู้บนโลกให้เป็น Formal Knowledge งั้นเราก็ให้ Computer เรียนรู้และสร้างความรู้เองเลยเป็นไงละ การที่ Computer เรียนรู้จากข้อมูลและสร้างองค์ความรู้ขึ้นมาเองในบริบทนั้นๆ เราเรียกว่า Machine (Automatic) Learning (ตรงตัวมากจริง เครื่องจักรที่เกิดการเรียนรู้)\n",
    "\n",
    "## แนวคิดดูเจ๋งดีแต่มันทำงานจริงๆยังไง?\n",
    "ให้จินตาการว่าเราต้องการสร้างหุ่นยนต์ที่สามารถบอกเราว่า วันนี้เหมาะไปเที่ยวไหม ได้แก่ เที่ยว, ไม่เที่ยว โดยหุ่นยนต์ตัวนี้จะบอกคำตอบ(ที่น่าจะเป็น)เราได้ก็ต่อเมื่อมันสามารถรับสัญญาณได้ว่าวันนี้ อากาศเ็นยังไง, วันนี้คือวันอะไรของสัปดาห์ \n",
    "> Note: Input: [สภาพอากาศ, วันของสัปดาห์], Output: [เที่ยว, ไม่เที่ยว]\n",
    "\n",
    "จินตนาการว่าสมองของคุณยนต์เราคือสมการคณิตศาสตร์(อย่าพึ่งตกใจนะ เรายังไม่ได้เข้าไปสู่โลกของคณิตศาสตร์ แต่ที่ยกมาเพราะอยากสะท้อนสิ่งที่เกิดจริงๆในสอมงข้างในของหุ่นยนต์) ดังนั้นตัวแปรอิสระเราก็คือ Input และตัวแปรตามคือ Output เรานำ Input ไปทำ operation (+,-,x,/) กับตัวแปรอีกชุดขอเรียกว่า Weights ถ้าเราสุ่มค่าของ weights แต่ละตัว แล้วนำมาทำ operation กับ input ก็จะให้คำตอบออกมา แต่คำตอบพวกนี้คงอาจจะมีถูกบ้าง ไม่ถูกบ้าง(แน่นอนไม่เกิดจากการสุ่ม) ดังนั้นการเรียนรู้ของหุ่นยนต์เลยเกิดขึ้น ณ จุดๆนี้ สมองของหุ่นยนต์พยายามปรับ weights (ตัวแปรที่มีความสัมพันธ์กับ input เพื่อผลิต output) ให้ผลลัพธ์จากสมการมีความถูกต้องมากขึ้นเรื่อยๆ จนสุดท้ายเราจะได้ weights ที่เมื่อเจอกับ input จะสามารถให้คำตอบที่ถูกต้องได้ แน่นอนว่า input ของเราเป็นสิ่งที่ไม่ได้อยู่ในช่วงเรียนรู้ของหุ่นยนต์ได้ นั่นคือเราเอาหุ่นยนต์ไปใช้กับบ้านอื่นได้โดยมั่นใจได้ว่าหุ่นยนต์สามารถแก้ปัญหานี้ให้กับคนอื่นได้ เย้!\n",
    "> Important: เมื่อสมการผลิต output จะมีการนำ output ไปเทียบกับ output จริง เพื่อดูความถูกต้อง ดังนั้นเมื่อเกิด Error จะมีการแจ้งเตื่อนไปยัง weights เพื่อบอกว่าสถานะพวกคุณตอนนี้ทำให้ผลลัพธ์ที่ได้จากสมาการมีความผิดพลาด กรุณาทำการปรับค่าของพวกคุณให้เหมาะสมด้วย ขอบคุณครับ สุดท้าย weights ก็จะมีการปรับปรุงค่าจนถึงเวลาอันสมควรหรือ ผลลัพธ์ที่ได้มีความถูกต้องจนรับได้ ก็จะหยุดเรียนรู้ และเราสามารถนำ weights นั้นไปใช้งานจริงได้\n",
    "\n",
    "> Note: Weight: (Based On Context)Knowledge, Output: Information(Independent Variable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# พอแล้ว Machine Learning แล้ว Deep Learning มันคืออะไรละ\n",
    "\n",
    "ก่อนจะพูดถึง Deep Learning มาพูดถึงสิ่งหนึ่งก่อน\n",
    "## Neural Network \n",
    "Neural Network เกิดขึ้นมาจากการพยายามสร้างต้นแบบการทำงานของสมองมนุษย์ แต่ต้นแบบที่สร้างมาเอาจริงๆก็ไม่ใช่สิ่งที่สมองเป็นหรือทำงานในรูปแบบนี้ที่จำลองขึ้นมา โดย model ที่สร้างขึ้นมาเรียกว่า Perceptron โดยการทำงานคร่าวๆคือ Neuron ต่อไปขอเรียกว่า Node รับกระแสไฟฟ้า ต่อไปขอเรียกว่า weight (จาก nodes ที่เชื่อมต่อกับมัน) เข้ามาในที่นี้คือเอาค่าพลังงานที่ปล่อยออกจาก node ก่อนหน้า มาคูณกับ weight ที่เชื่อม และเนื่องจาก node หนึ่งสามารถถูกเชื่อมด้วย node ก่อนหน้าได้หลาย nodes ทำให้เกิดการคูณกันของ node กับ weight ที่เชื่อมต่อ เราเลยได้ค่าออกมาเท่ากับจำนวน nodes ก่อนหน้าที่เชื่อมต่อกับ node ที่เราสนใจดังนั้นเราเลยเอามันมารวมพลังกันเพื่อดูว่าผ่าน Threshold และ(ในอนาคตสิ่งนี้จะกลายเป็น Activation Function) จะสามารถปล่อยค่าพลังไป Node อื่นต่อไปได้หรือเปล่า \n",
    "\n",
    "แน่นอนว่า model ที่สร้างไม่ได้สะท้อนว่าจริงๆสมองเราทำงานแบบนี้ ดังนั้นเลยมีการปรับปรุงและพัฒนาต่อไปเรื่อยๆ แต่สุดท้าย Deep Learning ก็มีช่วงที่คนหมดความเชื่อถืออยู่ 2 ครั้ง \n",
    "> Note: ครั้งที่ 1 เกิดจากการที่ Neural network program ไม่สามารถแก้ไขปัญหาที่มีชื่อว่า XOR (Neural Network มีเพียง 1 layer)ได้ซึ่งเป็นปัญหาที่ simple แต่ในบทความที่เขียนถึงข้อสังเกตนี้ก็ได้บอกต่อว่าปัญหา XOR นี้สามารถแก้ไขได้เมื่อเราเพิ่มจำนวน Layer ให้กับ Network program  แต่สุดท้ายประเด็นแรกก็ถูกยกขึ้นมาและถูกสนใจมากกว่าประเด็นที่ 2 มาก จนคนหมดความหวังกับ Neural Network ขอต้อนรับสู่ Deep Learning Winter ครี่งที่ 1\n",
    "\n",
    "> Note: ครั้งที่ 2 เรารู้ถึงไอเดียแล้วว่า neural network สามารถแก้ไขทุกอย่างได้โดยการเพิ่ม layer ทั้งหมดเป็น 2 layers แต่สุดท้ายจะแก้ไขปัญหาให้จบเพียง 2 layers บางปัญหามีความซับซ้อนมากต้องอาศัย patameters (weights) จำนวนมาก นั้นหมายถึงต้องการพลังในการประมวลผลที่สูงและจำนวนข้อมูลที่มาก (Overfitting) นั้นทำให้คนเริ่มหมดความหวังกับ Deep Learning ขอต้อนรับสู่ Deep Learning Winter ครั้งที่ 2 ต่อมามีคนค้นพบว่าปัญหานี้แก้ได้่โดยการเพิ่ม layer มากขึ้นไปอีกมากกว่า 2 layers จำนวน parameters สามารถเพิ่มขึ้นได้โดยที่ไม่ทำให้เกิดการคำนวณมากเกินไป\n",
    "\n",
    "## ปะวัติโดยย่อมากๆของ Deep Learning และถือโอกาสขอบคุณทุกคนที่มีส่วนร่วมในประวัติศาสตร์ครั้งนี้\n",
    "Deep Learning ที่กำลังเป็นส่วนสำคัญในการสร้างอนาคตไปด้วยกันกับเรา เกือบที่จะหายไปหลายครั้งแล้วแต่โชคดีที่เรามีคนที่อยู่เบื้องหลังที่ยังคอยพัฒนา, วิจัยและพยุง Deep Learning ให้สามารถดำเนินต่อไปได้ หลังจากที่ผ่านช่วง Hype และมีความคาดหวังที่สูง neural network ก็ถูกปัดออกจากสิ่งที่เคยเป็นที่น่าสนใจของคนหมู่มากในช่วง 1990s และ 2000s และมีเพียงนักวิจัยไม่มากที่ยังคอยพัฒนาและมีความเชื่อว่าซักวันจะถึงเวลาของพระเอกของเรา Deep Learning! \n",
    "\n",
    "โดยผู้อยู่เบื้องหลังทั้ง 3 คนที่ยังคงมีความเชื่อมั่นว่า Deep Learning คืออนาคตของ AI ได้แก่ Yann Lecun, Yoshua Bengio, and Geoffrey Hinton ทั้ง 3 เป็นผู้ที่ได้รับรางวัล Turing Award ซึ่งเป็นรางวัลสูงสุดของสายงาน Computer Science เปรียบได้กับได้ออสการ์จากวงการภาพยนต์ Lecun ได้ทำงานเกี่ยวกับ Convolutional Neural Network (CNN) ได้สร้าง Deep Learning program ที่สามารถบอกได้ว่าตัวเลขที่เขียนด้วยมือเป็นเลขอะไร (MNIST Dataset) และถูกนำไปใช้ในการแ่มุมธุรกิจเพื่อใช้อ่านตัวเลขจากลายมือ 10% จากงานทั้งหมดที่เกิดขึ้นใน US \n",
    "\n",
    "จริงๆแล้วไม่ได้มีแค่ 3 คนที่ยังคอยพยุง ยังมีนักวิจัยอีกบางส่วนที่ได้สร้างไอเดียที่สำคัญและปัจจุบันก็เป็นเทคนิคที่นิยมมากๆนั้นคือ Long Shot Term Memory (LSTM) โดย Jurgen Schmidhuber และนักเรียนชื่อ Sepp Hocheriter \n",
    "\n",
    "นอกจากนี้ในปี 1974 Paul Werbos ได้คิดค้นเทคนิคที่มีชื่อว่า Back Propagation เทคนิคที่ปัจจุบันถูกใช้เป็นเทคนิคหลักในการเรียนรู้ของ neural network program ถึงแม้ว่าเทคนิคนี้จะทรงพลังแค่ไหนก็ยังถูกมองข้ามเป็นหลักสิบปี เพราะคนไม่ให้ความสำคัญกับ Neural Network แต่ในปัจจุบัน back Propagation คือเทคนิคสำคัญก็การสร้าง AI ในยุคปัจจุบันด้วย Deep Learning\n",
    "\n",
    "จะเห็นว่า Deep Larning ได้ผ่านช่วงที่อยากลำบากมาหลายครั้ง ถ้าเราไม่มีคนที่คอยวิจัยและผลักดันก็จะไม่เกิดสิ่งที่เราให้ความสนใจอยู่ในปัจจุบันและสิ่งที่เป็นกำลังหลักในการสร้างอนาคตและยกระดับความสามารถของมนุษย์ขึ้นไปอีกขั้น\n",
    "\n",
    "ต้องขอขอบคุณทุกคนที่มีส่วนในการสร้างและผลักดันในอดีตและปัจจุบัน โดยปัจจุบันผลลัพธ์ของสิ่งนั้นได้เห็นผลแล้วและคนก็มีความสนใจกันมากขึ้น รวมถึงการทำให้ Deep Learning เข้าถึงได้งาน เช่น Framework ต่างๆ  ความคาดหวังของผมต่อไปคือการไปต่อและสร้างความก้าวหน้าในสิ่งที่เรายังไม่รู้ในตอนนี้"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ในปี 1943 เรามี model แรก ที่พยายามใช้ในการทำความเข้าใจการทำงานของสมองมนุษย์\n",
    "- ช่วงปี 1950 Perceptron model สามารถปรับ weights ได้ด้วยตนเอง (ไม่มีมนุษย์มาคอยดูและปรับ) ด้วย optimization algorithm ที่มีชื่อว่า SGD แต่ก็แก้ไขได้แค่่ปัญหาที่เป็น linear function\n",
    "- ในปี 1969 Perceptron model ไม่สามารถแก้ไขปัญหา non linear functions ได้ ซึ่งประเด็นนี้ทำให้งานวิจัย neural network แทบจะถูกทิ้งและไม่ได้รับความสนใจ\n",
    "- มีกลุ่มของนักวิจัยที่ยังพัฒนาและสร้าง neural network อย่างเงียบๆ\n",
    "- ประมาณช่วง 1970s มีการคิดค้น Back propagation algorithm ใช้สำหรับการเรียนรู้ของ neural network ที่มีมากกว่า 2 layers แต่ก็ยังไม่เป็นที่นิยมเพราะต้องการพลังงานในการประมวลผลและข้อมูลจำนวนมาก\n",
    "- ในปี 1988 เรามี CNN เกิดขึ้นบนโลกเรา\n",
    "- ประมาณปี 2000 Deep learning เริ่มกับมาเป็นที่สนใจ ต้องขอบคุณพลังของการประมวลผล(ขอบคุณ GPUs) จำนวนข้อมูลที่มากและมีการสร้าง Datasets กันแบบจริงจัง รวมถึงการทำเป็น Standard เพื่อกระตุ้นให้เกิดการพัฒนาอย่างต่อเนื่อง รวมถึง Software ในแง่การสร้างพัฒนา และในแง่การเรียนรู้ของ Computer ผ่านการทำงานแบบ Distributed  \n",
    "\n",
    "## แล้วจริงๆ Deep Laerning คืออะไรถ้าเราไม่มองมันเป็นการจพลองการทำงานของสมองมนุษย์\n",
    "ผมมอง Deep Laerning ในแง่ของการเป็น program หรือจะพูดแบบเจาะจงคือ Multi Step Program โดยแต่ละ layer คือ represntation state ของข้อมูล (หรือ state ความคิดของ program ณ จุดนั้นๆ) โดยในแต่ละ step เราทำการปรับปรุง state (representation) โดยการนำมาผ่าน Simple Non Linear function เพื่อที่จะได้ state ใหม่ที่ถูกปรับปรุง จะสังเกตได่ว่า program มีการคำนวณเป็น step และทุก step เราจะได้ representation state ที่มีความ High level, abstracted และ Meaningful \n",
    "ลองจินตนาการว่า ถ้าเราต้องเขียนสมการที่ทำการ transform รูปภาพ ให้กลายเป็นการตรวจจับว่า มีรถ หรือคนในรูปไหม ตัวสมการจะมีความยากและซับซ้อนมากๆ แต่ถ้าเราแบ่งมันออกมาเป็น step by step โดยการผ่านรูปภาพไปยัง step แรกเราจะได้ representation ใหม่ออกมาที่บอกว่าในรูปเรามี edge ที่ทำมุมต่างๆที่เราสนใจไหม จากนั้นเอาข้อมูลนี้ไปผ่าน step ที่ 2 จะได้ representation ออกมาว่ามีรูปทรงต่างๆเหล่านี้บ้างไหม แล้วเมื่อเราผ่านแต่ละ steps ไปเรื่อยๆ สุดท้ายเราก็จะเจอ step ที่ทำหน้าที่ในการตรวจจับว่าจาก representation นี้มีคนหรือรถอยู่บ้างไหม\n",
    "แทนที่เราจะคิดสมการที่ซับซ้อนสามารถให้คำตอบว่ามีรถหรือคนไหมจาก input ที่เป็นรูปภาพ หรือการใช้ step เดียว ซึ่งต่ออาศัย parameters และการคำนวณมหาศาล เราแตกย่อยออกมาเป็นหลายๆ step โดยแต่ละ step ทำการ transform ด้วยสมการที่ไม่ซับซ้อน\n",
    "## มีการพูดถึง Representation บ่อยมากแสดงว่ามันสำคัญใช่ไหม\n",
    "ประเด็นหลักของ Deep Learning คือเราจะหา representation ที่ดีหรือเหมาะสมยังไง ลองคิดดูว่าถ้าเราต้องค้นหาเลขที่เราสนใจจากข้อมูล array ที่มีขนาดใหญ่มาก จาก 2 array ที่มีข้อมูลข้างในเหมือนกันทุกอย่างแต่ต่างกันตรงที่\n",
    "1. Array ที่มีการเรียงจากน้อยไปหามาก\n",
    "2. Array ที่ไม่มีการเรียงลำดับ\n",
    "คืดว่าแบบไหนจะทำให้เราหาเลขที่เราสนใจได้สะดวกกว่ากัน คำตอบก็คือแบบที่ 2 ดังนั้นสิ่งที่ Deep learning ทำคือ การหา Representation ที่ดี เพื่อที่เราจะสามารถอก้ไขปัญหาได้โดยการใช้เพียง Simple Linear Function (Output layer ใช้ weight sum ในกรณีต้องการคำตอบที่เป็น continuous value) \n",
    "Deep Laerning ทำการสร้าง Hirarchical Representation Learning โดยเมื่อผ่าน step 1 มาแล้วอาจจะยังไม่ใช่ Representation ที่ดีที่สุด\n",
    "> Note: representation ที่บอกว่าเจอ edges มุมต่างๆไหม ยังไม่มีความหมายเอามาใช้บอกได้ว่ามีคนหรือรถอยู่ในภาพไหม เพราะผลลัพธ์จากการตรวจจับว่าเกิดเส้นด้วยมุมต่างๆมันสามารถเปลี่ยนแปลงได้ตามปัจจัยที่ส่งผลให้ภาพเปลี่ยนแปลงเช่น การเคลื่อนที่ของ object, แสง เป็นต้น (ยกเว้นภาพนี้จะไม่มีปัจจัยเหล่านี้เข้ามากระทบ เราก็อาจจะตั้งสมมุติฐานได้ว่าถ้าเกิดเส้นองศาตามนี้ ที่ตำแหน่งนี้ ก็แปลว่ามีคน แต่ในโลกความเป็นจริงจะไม่เป็นเช่นนี้)\n",
    "\n",
    "ดังนั้นจึงทำการไป step ต่อไป ต่อเรื่อยๆ จนสุดท้ายได้ Representation ที่เหมาะสมที่สามารถให้คำตอบของปัญหาได้โดยการผ่าน Simple (Non) Linear Function \n",
    "\n",
    "## เราสามารถมอง Deep Laerning เป็น program ได้ และถ้าเรามองในรูปแบบ Computation Graph\n",
    "- ความลึกของ Graph คือ steps ในรูปแบบ Sequence (Layers)\n",
    "- ความกว้างของ Graph คือ steps ในรูปแบบ Parallel (Nodes ในแต่ละ layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ขอบคุณครับ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
